2022-01-23 19:06:48:INFO:-------------Round number: 0-------------
2022-01-23 19:06:48:INFO:-------------Sending models-------------
2022-01-23 19:06:49:INFO:-------------Evaluating models-------------
2022-01-23 19:06:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:06:49:INFO:Accuracy = [0.9230769230769231, 0.9134615384615384, 0.8942307692307693, 0.08653846153846154, 0.9228846153846154, 0.10576923076923077, 0.9038461538461539, 0.09634615384615385, 0.875, 0.3219230769230769]
2022-01-23 19:06:49:INFO:Loss = [0.6611255590732281, 0.6167901272957141, 0.6743974450689095, 0.717843431692857, 0.6765841778654319, 0.7541807597646346, 0.6252960620018152, 0.7044952930166171, 0.6695327019462218, 0.6945109390295469]
2022-01-23 19:06:49:INFO:-------------Training local models-------------
2022-01-23 19:11:01:INFO:-------------Aggregating local models-------------
2022-01-23 19:11:04:INFO:-------------Round number: 1-------------
2022-01-23 19:11:04:INFO:-------------Sending models-------------
2022-01-23 19:11:04:INFO:-------------Evaluating models-------------
2022-01-23 19:11:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:11:04:INFO:Accuracy = [0.8653846153846154, 0.8546153846153847, 0.8142307692307692, 0.8586538461538461, 0.8940384615384616, 0.8701923076923077, 0.9038461538461539, 0.8742307692307693, 0.8588461538461538, 0.8209615384615384]
2022-01-23 19:11:04:INFO:Loss = [0.40944152980899584, 0.4030205849647665, 0.479700503557419, 0.38815103080840063, 0.35349711988909316, 0.4456957452079783, 0.3939611669271611, 0.44341535611937827, 0.4472491766164939, 0.5714245864118521]
2022-01-23 19:11:04:INFO:-------------Training local models-------------
2022-01-23 19:15:17:INFO:-------------Aggregating local models-------------
2022-01-23 19:15:20:INFO:-------------Round number: 2-------------
2022-01-23 19:15:20:INFO:-------------Sending models-------------
2022-01-23 19:15:20:INFO:-------------Evaluating models-------------
2022-01-23 19:15:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:15:20:INFO:Accuracy = [0.8653846153846154, 0.8530769230769231, 0.8209615384615384, 0.8623076923076923, 0.8942307692307693, 0.8651923076923077, 0.9038461538461539, 0.8846153846153846, 0.8657692307692307, 0.8303846153846154]
2022-01-23 19:15:20:INFO:Loss = [0.4171777314085585, 0.3980571169433041, 0.47288727140179476, 0.3420996563732982, 0.3255182579652263, 0.43014354185344505, 0.3843958301899525, 0.39558168403275956, 0.45185471940427446, 0.5805901118661635]
2022-01-23 19:15:20:INFO:-------------Training local models-------------
2022-01-23 19:19:33:INFO:-------------Aggregating local models-------------
2022-01-23 19:19:35:INFO:-------------Round number: 3-------------
2022-01-23 19:19:35:INFO:-------------Sending models-------------
2022-01-23 19:19:35:INFO:-------------Evaluating models-------------
2022-01-23 19:19:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:19:36:INFO:Accuracy = [0.8653846153846154, 0.8505769230769231, 0.8321153846153846, 0.865576923076923, 0.8942307692307693, 0.8661538461538462, 0.9038461538461539, 0.8846153846153846, 0.865576923076923, 0.8348076923076924]
2022-01-23 19:19:36:INFO:Loss = [0.4142671287252317, 0.395840740588028, 0.4696148981993946, 0.3219170078003887, 0.3102372708605029, 0.42061962302810013, 0.3835862735286355, 0.3727070623426698, 0.46038236098292357, 0.5799308020773773]
2022-01-23 19:19:36:INFO:-------------Training local models-------------
2022-01-23 19:23:49:INFO:-------------Aggregating local models-------------
2022-01-23 19:23:51:INFO:-------------Round number: 4-------------
2022-01-23 19:23:51:INFO:-------------Sending models-------------
2022-01-23 19:23:51:INFO:-------------Evaluating models-------------
2022-01-23 19:23:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:23:52:INFO:Accuracy = [0.8653846153846154, 0.8465384615384616, 0.8342307692307692, 0.8684615384615385, 0.8946153846153846, 0.8665384615384616, 0.9038461538461539, 0.8846153846153846, 0.8638461538461538, 0.8371153846153846]
2022-01-23 19:23:52:INFO:Loss = [0.4110426764941971, 0.39545592935442425, 0.4690968659426569, 0.31291877585933364, 0.3004153461952228, 0.41796988798439716, 0.3834611466154456, 0.3607609667244385, 0.4665782142658897, 0.5795911056114934]
2022-01-23 19:23:52:INFO:-------------Training local models-------------
2022-01-23 19:28:05:INFO:-------------Aggregating local models-------------
2022-01-23 19:28:07:INFO:-------------Round number: 5-------------
2022-01-23 19:28:07:INFO:-------------Sending models-------------
2022-01-23 19:28:07:INFO:-------------Evaluating models-------------
2022-01-23 19:28:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:28:08:INFO:Accuracy = [0.8653846153846154, 0.8403846153846154, 0.8359615384615384, 0.869423076923077, 0.8957692307692308, 0.8661538461538462, 0.905, 0.8848076923076923, 0.8634615384615385, 0.8365384615384616]
2022-01-23 19:28:08:INFO:Loss = [0.4138297999989635, 0.3945829688555722, 0.47085203366609324, 0.3091117047689085, 0.29468142297208455, 0.4182403269369388, 0.3827875837809048, 0.35460470840133407, 0.4706772964552958, 0.5816047843366575]
2022-01-23 19:28:08:INFO:-------------Training local models-------------
2022-01-23 19:32:21:INFO:-------------Aggregating local models-------------
2022-01-23 19:32:23:INFO:-------------Round number: 6-------------
2022-01-23 19:32:23:INFO:-------------Sending models-------------
2022-01-23 19:32:23:INFO:-------------Evaluating models-------------
2022-01-23 19:32:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:32:24:INFO:Accuracy = [0.8657692307692307, 0.8388461538461538, 0.8369230769230769, 0.8690384615384615, 0.8975, 0.8648076923076923, 0.9063461538461538, 0.8848076923076923, 0.8642307692307692, 0.8348076923076924]
2022-01-23 19:32:24:INFO:Loss = [0.4246408593328222, 0.3926023656777733, 0.4751262426938271, 0.30780380417015224, 0.2921818505632333, 0.42017366075742757, 0.38325505669210824, 0.3518039780812195, 0.474627359851953, 0.5857406420780955]
2022-01-23 19:32:24:INFO:-------------Training local models-------------
2022-01-23 19:36:37:INFO:-------------Aggregating local models-------------
2022-01-23 19:36:39:INFO:-------------Round number: 7-------------
2022-01-23 19:36:39:INFO:-------------Sending models-------------
2022-01-23 19:36:40:INFO:-------------Evaluating models-------------
2022-01-23 19:36:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:36:40:INFO:Accuracy = [0.8659615384615384, 0.8390384615384615, 0.8359615384615384, 0.8709615384615385, 0.8984615384615384, 0.8636538461538461, 0.9067307692307692, 0.8840384615384616, 0.8636538461538461, 0.8296153846153846]
2022-01-23 19:36:40:INFO:Loss = [0.44102284655337615, 0.39015119069909604, 0.48121201661930313, 0.307441288778836, 0.29155740260522667, 0.42181141763117364, 0.38424155418089445, 0.35214017231751665, 0.4810256344678167, 0.5921214249504444]
2022-01-23 19:36:40:INFO:-------------Training local models-------------
2022-01-23 19:40:53:INFO:-------------Aggregating local models-------------
2022-01-23 19:40:55:INFO:-------------Round number: 8-------------
2022-01-23 19:40:55:INFO:-------------Sending models-------------
2022-01-23 19:40:55:INFO:-------------Evaluating models-------------
2022-01-23 19:40:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:40:56:INFO:Accuracy = [0.8659615384615384, 0.8373076923076923, 0.8363461538461539, 0.8703846153846154, 0.9003846153846153, 0.864423076923077, 0.9075, 0.8840384615384616, 0.8621153846153846, 0.8303846153846154]
2022-01-23 19:40:56:INFO:Loss = [0.46358735047285266, 0.3883366270221394, 0.4873871503480656, 0.3074790018771847, 0.29198943657236387, 0.4234067809386313, 0.38524474124110736, 0.3548875408439646, 0.4867915852782272, 0.5968382584687788]
2022-01-23 19:40:56:INFO:-------------Training local models-------------
2022-01-23 19:45:08:INFO:-------------Aggregating local models-------------
2022-01-23 19:45:11:INFO:-------------Round number: 9-------------
2022-01-23 19:45:11:INFO:-------------Sending models-------------
2022-01-23 19:45:11:INFO:-------------Evaluating models-------------
2022-01-23 19:45:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:45:11:INFO:Accuracy = [0.8653846153846154, 0.8388461538461538, 0.8359615384615384, 0.8690384615384615, 0.9015384615384615, 0.8636538461538461, 0.9075, 0.8834615384615384, 0.8619230769230769, 0.8317307692307693]
2022-01-23 19:45:11:INFO:Loss = [0.48852946911098954, 0.3871656918110183, 0.49298878225202386, 0.3074917801350239, 0.29272881782806226, 0.42505788961660496, 0.38663801573700485, 0.35931234517584715, 0.4907055432167209, 0.5987445247614792]
2022-01-23 19:45:11:INFO:-------------Training local models-------------
2022-01-23 19:49:24:INFO:-------------Aggregating local models-------------
2022-01-23 19:49:26:INFO:-------------Round number: 10-------------
2022-01-23 19:49:26:INFO:-------------Sending models-------------
2022-01-23 19:49:26:INFO:-------------Evaluating models-------------
2022-01-23 19:49:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:49:27:INFO:Accuracy = [0.8653846153846154, 0.8398076923076923, 0.835, 0.8686538461538461, 0.9028846153846154, 0.8630769230769231, 0.9067307692307692, 0.8830769230769231, 0.8626923076923076, 0.8321153846153846]
2022-01-23 19:49:27:INFO:Loss = [0.5119009377068813, 0.3871417663243707, 0.49618103575015154, 0.3072345710063998, 0.2941788654940095, 0.4269830847579914, 0.3886818243660785, 0.3648553688427245, 0.4933283640913522, 0.5994260877028305]
2022-01-23 19:49:27:INFO:-------------Training local models-------------
2022-01-23 19:53:39:INFO:-------------Aggregating local models-------------
2022-01-23 19:53:42:INFO:-------------Round number: 11-------------
2022-01-23 19:53:42:INFO:-------------Sending models-------------
2022-01-23 19:53:42:INFO:-------------Evaluating models-------------
2022-01-23 19:53:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:53:42:INFO:Accuracy = [0.8653846153846154, 0.8403846153846154, 0.835, 0.8690384615384615, 0.9036538461538461, 0.8626923076923076, 0.9055769230769231, 0.8828846153846154, 0.8634615384615385, 0.8305769230769231]
2022-01-23 19:53:42:INFO:Loss = [0.5304434614725044, 0.3881494314947094, 0.4973690916337476, 0.3066752215577603, 0.29567333950231284, 0.4292222474871848, 0.39159179077810574, 0.36978992373434055, 0.49450794045920843, 0.5998640859962996]
2022-01-23 19:53:42:INFO:-------------Training local models-------------
2022-01-23 19:57:54:INFO:-------------Aggregating local models-------------
2022-01-23 19:57:57:INFO:-------------Round number: 12-------------
2022-01-23 19:57:57:INFO:-------------Sending models-------------
2022-01-23 19:57:57:INFO:-------------Evaluating models-------------
2022-01-23 19:57:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:57:57:INFO:Accuracy = [0.8653846153846154, 0.8421153846153846, 0.8348076923076924, 0.8707692307692307, 0.9048076923076923, 0.8611538461538462, 0.9057692307692308, 0.8828846153846154, 0.8632692307692308, 0.8311538461538461]
2022-01-23 19:57:57:INFO:Loss = [0.5439155001838046, 0.3900842504607191, 0.49779195269981685, 0.30585815597609883, 0.29732758120987385, 0.43201260517973705, 0.3948013775471526, 0.3737695382044946, 0.49456375845329603, 0.599405767836008]
2022-01-23 19:57:57:INFO:-------------Training local models-------------
2022-01-23 20:02:08:INFO:-------------Aggregating local models-------------
2022-01-23 20:02:10:INFO:-------------Round number: 13-------------
2022-01-23 20:02:10:INFO:-------------Sending models-------------
2022-01-23 20:02:10:INFO:-------------Evaluating models-------------
2022-01-23 20:02:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:02:11:INFO:Accuracy = [0.8653846153846154, 0.8419230769230769, 0.8367307692307693, 0.8723076923076923, 0.9051923076923077, 0.8609615384615384, 0.9055769230769231, 0.8836538461538461, 0.8636538461538461, 0.83]
2022-01-23 20:02:11:INFO:Loss = [0.5538916532241274, 0.39289661587491326, 0.49722891998121316, 0.30480672907064077, 0.29891098930238513, 0.4351313841627696, 0.3977430825918698, 0.37702400122753504, 0.4941194354642693, 0.5988228896536524]
2022-01-23 20:02:11:INFO:-------------Training local models-------------
2022-01-23 20:06:21:INFO:-------------Aggregating local models-------------
2022-01-23 20:06:23:INFO:-------------Round number: 14-------------
2022-01-23 20:06:23:INFO:-------------Sending models-------------
2022-01-23 20:06:23:INFO:-------------Evaluating models-------------
2022-01-23 20:06:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:06:23:INFO:Accuracy = [0.8653846153846154, 0.8423076923076923, 0.8384615384615385, 0.8736538461538461, 0.9053846153846153, 0.8598076923076923, 0.9053846153846153, 0.8840384615384616, 0.8632692307692308, 0.8319230769230769]
2022-01-23 20:06:23:INFO:Loss = [0.5618668059497185, 0.3971049891624716, 0.4965038570019085, 0.3036074203465922, 0.30094309928077007, 0.4385979701988757, 0.4004407028506438, 0.37978104439893146, 0.49335362219426315, 0.5990607042622287]
2022-01-23 20:06:23:INFO:-------------Training local models-------------
2022-01-23 20:10:33:INFO:-------------Aggregating local models-------------
2022-01-23 20:10:35:INFO:-------------Round number: 15-------------
2022-01-23 20:10:35:INFO:-------------Sending models-------------
2022-01-23 20:10:36:INFO:-------------Evaluating models-------------
2022-01-23 20:10:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:10:36:INFO:Accuracy = [0.8653846153846154, 0.8419230769230769, 0.8407692307692308, 0.8763461538461539, 0.9059615384615385, 0.8603846153846154, 0.905, 0.8846153846153846, 0.8640384615384615, 0.8319230769230769]
2022-01-23 20:10:36:INFO:Loss = [0.5679576737524118, 0.4028128049246264, 0.49565214084549764, 0.302265214027172, 0.3034634492180955, 0.44252845004470703, 0.40315794324739657, 0.3822357990978232, 0.4922873817102719, 0.5998698058235907]
2022-01-23 20:10:36:INFO:-------------Training local models-------------
2022-01-23 20:14:45:INFO:-------------Aggregating local models-------------
2022-01-23 20:14:48:INFO:-------------Round number: 16-------------
2022-01-23 20:14:48:INFO:-------------Sending models-------------
2022-01-23 20:14:48:INFO:-------------Evaluating models-------------
2022-01-23 20:14:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:14:48:INFO:Accuracy = [0.8653846153846154, 0.8403846153846154, 0.8428846153846153, 0.8767307692307692, 0.9057692307692308, 0.8603846153846154, 0.9046153846153846, 0.8857692307692308, 0.8648076923076923, 0.8315384615384616]
2022-01-23 20:14:48:INFO:Loss = [0.5735302153320495, 0.41035804997451264, 0.49493300592355527, 0.30096005268541587, 0.3063030836078374, 0.44667796292840367, 0.4059496333043521, 0.38463975270552997, 0.4915639730967926, 0.6015750280790738]
2022-01-23 20:14:48:INFO:-------------Training local models-------------
2022-01-23 20:18:58:INFO:-------------Aggregating local models-------------
2022-01-23 20:19:00:INFO:-------------Round number: 17-------------
2022-01-23 20:19:00:INFO:-------------Sending models-------------
2022-01-23 20:19:00:INFO:-------------Evaluating models-------------
2022-01-23 20:19:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:19:01:INFO:Accuracy = [0.8653846153846154, 0.8376923076923077, 0.8432692307692308, 0.8784615384615385, 0.9063461538461538, 0.86, 0.9040384615384616, 0.8867307692307692, 0.8648076923076923, 0.8309615384615384]
2022-01-23 20:19:01:INFO:Loss = [0.5782523555543986, 0.41981926810387027, 0.4942733398146139, 0.2997521446145234, 0.30966760289503814, 0.4514058552371213, 0.40868536950326345, 0.38697844504741413, 0.49112133051844115, 0.6042052804550622]
2022-01-23 20:19:01:INFO:-------------Training local models-------------
2022-01-23 20:23:11:INFO:-------------Aggregating local models-------------
2022-01-23 20:23:13:INFO:-------------Round number: 18-------------
2022-01-23 20:23:13:INFO:-------------Sending models-------------
2022-01-23 20:23:13:INFO:-------------Evaluating models-------------
2022-01-23 20:23:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:23:14:INFO:Accuracy = [0.8653846153846154, 0.8359615384615384, 0.8465384615384616, 0.8788461538461538, 0.9071153846153847, 0.8596153846153847, 0.9042307692307693, 0.8861538461538462, 0.8661538461538462, 0.8296153846153846]
2022-01-23 20:23:14:INFO:Loss = [0.581733995675537, 0.4314642540065016, 0.493414328401671, 0.29874590647551275, 0.3124319798930978, 0.45649460169876804, 0.4113335795946813, 0.38937705207158263, 0.4909114824068428, 0.6075410665216623]
2022-01-23 20:23:14:INFO:-------------Training local models-------------
2022-01-23 20:27:23:INFO:-------------Aggregating local models-------------
2022-01-23 20:27:26:INFO:-------------Round number: 19-------------
2022-01-23 20:27:26:INFO:-------------Sending models-------------
2022-01-23 20:27:26:INFO:-------------Evaluating models-------------
2022-01-23 20:27:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:27:26:INFO:Accuracy = [0.8653846153846154, 0.8305769230769231, 0.8471153846153846, 0.8801923076923077, 0.9075, 0.8601923076923077, 0.9040384615384616, 0.8857692307692308, 0.8669230769230769, 0.8276923076923077]
2022-01-23 20:27:26:INFO:Loss = [0.5852640688857579, 0.44544322057789454, 0.49264240056604297, 0.29826233030941623, 0.31589369579104154, 0.4615703733501365, 0.4140180331383957, 0.39192790860061694, 0.4910217581522235, 0.6113611400572924]
2022-01-23 20:27:26:INFO:-------------Training local models-------------
2022-01-23 20:31:36:INFO:-------------Aggregating local models-------------
2022-01-23 20:31:38:INFO:-------------Round number: 20-------------
2022-01-23 20:31:38:INFO:-------------Sending models-------------
2022-01-23 20:31:38:INFO:-------------Evaluating models-------------
2022-01-23 20:31:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:31:39:INFO:Accuracy = [0.8653846153846154, 0.8265384615384616, 0.8498076923076923, 0.8813461538461539, 0.9073076923076923, 0.859423076923077, 0.9040384615384616, 0.8859615384615385, 0.8673076923076923, 0.8263461538461538]
2022-01-23 20:31:39:INFO:Loss = [0.5882782002699969, 0.4594208967763944, 0.49185865301072995, 0.298476827381819, 0.3194701599892981, 0.46642635771898383, 0.4167770590451815, 0.39440939718462265, 0.4915354605792135, 0.6158202270190276]
2022-01-23 20:31:39:INFO:-------------Training local models-------------
2022-01-23 20:35:48:INFO:-------------Aggregating local models-------------
2022-01-23 20:35:51:INFO:-------------Round number: 21-------------
2022-01-23 20:35:51:INFO:-------------Sending models-------------
2022-01-23 20:35:51:INFO:-------------Evaluating models-------------
2022-01-23 20:35:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:35:51:INFO:Accuracy = [0.8653846153846154, 0.8242307692307692, 0.8523076923076923, 0.8832692307692308, 0.9073076923076923, 0.8596153846153847, 0.9038461538461539, 0.8861538461538462, 0.8678846153846154, 0.8251923076923077]
2022-01-23 20:35:51:INFO:Loss = [0.5917953136858369, 0.4727757657671576, 0.49111417012220326, 0.2990817247059917, 0.32291079228665553, 0.47106700063900814, 0.4194652890465267, 0.39731780448010584, 0.4926397176090037, 0.6210839171863671]
2022-01-23 20:35:51:INFO:-------------Training local models-------------
2022-01-23 20:40:01:INFO:-------------Aggregating local models-------------
2022-01-23 20:40:03:INFO:-------------Round number: 22-------------
2022-01-23 20:40:03:INFO:-------------Sending models-------------
2022-01-23 20:40:04:INFO:-------------Evaluating models-------------
2022-01-23 20:40:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:40:04:INFO:Accuracy = [0.8653846153846154, 0.8228846153846154, 0.8532692307692308, 0.8846153846153846, 0.9071153846153847, 0.8592307692307692, 0.9038461538461539, 0.8861538461538462, 0.8675, 0.8248076923076924]
2022-01-23 20:40:04:INFO:Loss = [0.5956381560175102, 0.4846402071416378, 0.490031349507822, 0.29995650111539784, 0.3264756851925855, 0.4754900909889469, 0.42198749818075715, 0.4003609616671523, 0.4938476093930848, 0.6261769144755538]
2022-01-23 20:40:04:INFO:-------------Training local models-------------
2022-01-23 20:44:13:INFO:-------------Aggregating local models-------------
2022-01-23 20:44:16:INFO:-------------Round number: 23-------------
2022-01-23 20:44:16:INFO:-------------Sending models-------------
2022-01-23 20:44:16:INFO:-------------Evaluating models-------------
2022-01-23 20:44:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:44:16:INFO:Accuracy = [0.8653846153846154, 0.8234615384615385, 0.8534615384615385, 0.8846153846153846, 0.9073076923076923, 0.8590384615384615, 0.9036538461538461, 0.8859615384615385, 0.8678846153846154, 0.8225]
2022-01-23 20:44:16:INFO:Loss = [0.5992923210489187, 0.49383903990481204, 0.48898305480766935, 0.30087513467515237, 0.32977164546341203, 0.4796905447923424, 0.42448694949416677, 0.40350060064912, 0.49524674867517693, 0.6312368947630882]
2022-01-23 20:44:16:INFO:-------------Training local models-------------
2022-01-23 20:48:26:INFO:-------------Aggregating local models-------------
2022-01-23 20:48:28:INFO:-------------Round number: 24-------------
2022-01-23 20:48:28:INFO:-------------Sending models-------------
2022-01-23 20:48:29:INFO:-------------Evaluating models-------------
2022-01-23 20:48:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:48:29:INFO:Accuracy = [0.8653846153846154, 0.8221153846153846, 0.8546153846153847, 0.8857692307692308, 0.9080769230769231, 0.8592307692307692, 0.9038461538461539, 0.8853846153846154, 0.8686538461538461, 0.8221153846153846]
2022-01-23 20:48:29:INFO:Loss = [0.6032998472290694, 0.5024770729723969, 0.48813133885932286, 0.30189445261259185, 0.33305260589482855, 0.4839278108356666, 0.42700286873766274, 0.4069901134309755, 0.49688307747209576, 0.6359404258798279]
2022-01-23 20:48:29:INFO:-------------Training local models-------------
2022-01-23 20:52:38:INFO:-------------Aggregating local models-------------
2022-01-23 20:52:41:INFO:-------------Round number: 25-------------
2022-01-23 20:52:41:INFO:-------------Sending models-------------
2022-01-23 20:52:41:INFO:-------------Evaluating models-------------
2022-01-23 20:52:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:52:41:INFO:Accuracy = [0.8653846153846154, 0.8223076923076923, 0.854423076923077, 0.8857692307692308, 0.9076923076923077, 0.86, 0.9034615384615384, 0.8853846153846154, 0.8690384615384615, 0.821923076923077]
2022-01-23 20:52:41:INFO:Loss = [0.6073524044471784, 0.5104358603693981, 0.48747232835446014, 0.30303295911205796, 0.3363718641961056, 0.48812383743433413, 0.42940995484745004, 0.41072102148371836, 0.49860636277662707, 0.6406343622265223]
2022-01-23 20:52:41:INFO:-------------Training local models-------------
2022-01-23 20:56:51:INFO:-------------Aggregating local models-------------
2022-01-23 20:56:54:INFO:-------------Round number: 26-------------
2022-01-23 20:56:54:INFO:-------------Sending models-------------
2022-01-23 20:56:54:INFO:-------------Evaluating models-------------
2022-01-23 20:56:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:56:54:INFO:Accuracy = [0.8653846153846154, 0.821923076923077, 0.8561538461538462, 0.8865384615384615, 0.9076923076923077, 0.8596153846153847, 0.9034615384615384, 0.885, 0.8692307692307693, 0.8209615384615384]
2022-01-23 20:56:54:INFO:Loss = [0.6115023428791084, 0.5171519296758421, 0.4871486960901865, 0.304304005548077, 0.33965815043092545, 0.4922878038203355, 0.43175211740610675, 0.41459752373688946, 0.5004793872530382, 0.6452385504336025]
2022-01-23 20:56:54:INFO:-------------Training local models-------------
2022-01-23 21:01:03:INFO:-------------Aggregating local models-------------
2022-01-23 21:01:06:INFO:-------------Round number: 27-------------
2022-01-23 21:01:06:INFO:-------------Sending models-------------
2022-01-23 21:01:06:INFO:-------------Evaluating models-------------
2022-01-23 21:01:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:01:06:INFO:Accuracy = [0.8653846153846154, 0.8223076923076923, 0.8563461538461539, 0.8871153846153846, 0.9078846153846154, 0.8598076923076923, 0.9038461538461539, 0.884423076923077, 0.8682692307692308, 0.82]
2022-01-23 21:01:06:INFO:Loss = [0.6155807478144897, 0.5234851464482255, 0.4871123604530462, 0.3057410024406496, 0.3423975760630968, 0.49633941917538604, 0.4338967227903105, 0.4186593143536951, 0.502457370279724, 0.649299440780921]
2022-01-23 21:01:06:INFO:-------------Training local models-------------
2022-01-23 21:05:16:INFO:-------------Aggregating local models-------------
2022-01-23 21:05:18:INFO:-------------Round number: 28-------------
2022-01-23 21:05:18:INFO:-------------Sending models-------------
2022-01-23 21:05:19:INFO:-------------Evaluating models-------------
2022-01-23 21:05:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:05:19:INFO:Accuracy = [0.8653846153846154, 0.8217307692307693, 0.8575, 0.8869230769230769, 0.9082692307692307, 0.8598076923076923, 0.9038461538461539, 0.8846153846153846, 0.8684615384615385, 0.8182692307692307]
2022-01-23 21:05:19:INFO:Loss = [0.6194192092124677, 0.5292366347971088, 0.4872075943890545, 0.30725035604420836, 0.34519318198279225, 0.5004847284878381, 0.43600769932751204, 0.4226242387604333, 0.5045749452866193, 0.6532308827562912]
2022-01-23 21:05:19:INFO:-------------Training local models-------------
2022-01-23 21:09:29:INFO:-------------Aggregating local models-------------
2022-01-23 21:09:31:INFO:-------------Round number: 29-------------
2022-01-23 21:09:31:INFO:-------------Sending models-------------
2022-01-23 21:09:31:INFO:-------------Evaluating models-------------
2022-01-23 21:09:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:09:32:INFO:Accuracy = [0.8653846153846154, 0.8213461538461538, 0.8578846153846154, 0.8882692307692308, 0.9082692307692307, 0.8613461538461539, 0.9034615384615384, 0.8846153846153846, 0.8692307692307693, 0.8178846153846154]
2022-01-23 21:09:32:INFO:Loss = [0.623076637142311, 0.5353673163467297, 0.4874207967607687, 0.3089162414405739, 0.34783598411181277, 0.5045015528748291, 0.4381082986113212, 0.4266783814669347, 0.5068159060547959, 0.6567119304353792]
2022-01-23 21:09:32:INFO:-------------Training local models-------------
2022-01-23 21:13:41:INFO:-------------Aggregating local models-------------
2022-01-23 21:13:44:INFO:-------------Round number: 30-------------
2022-01-23 21:13:44:INFO:-------------Sending models-------------
2022-01-23 21:13:44:INFO:-------------Evaluating models-------------
2022-01-23 21:13:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:13:44:INFO:Accuracy = [0.8653846153846154, 0.8213461538461538, 0.8571153846153846, 0.8888461538461538, 0.9080769230769231, 0.8609615384615384, 0.9034615384615384, 0.8842307692307693, 0.869423076923077, 0.8173076923076923]
2022-01-23 21:13:44:INFO:Loss = [0.6265242373781523, 0.5411997955020175, 0.4879065629763248, 0.31071007569894743, 0.3504898606952338, 0.5088600234448677, 0.4402466956111871, 0.4306870792171629, 0.5093800488006169, 0.6600981454539578]
2022-01-23 21:13:44:INFO:-------------Training local models-------------
2022-01-23 21:17:53:INFO:-------------Aggregating local models-------------
2022-01-23 21:17:56:INFO:-------------Round number: 31-------------
2022-01-23 21:17:56:INFO:-------------Sending models-------------
2022-01-23 21:17:56:INFO:-------------Evaluating models-------------
2022-01-23 21:17:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:17:56:INFO:Accuracy = [0.8653846153846154, 0.8217307692307693, 0.8571153846153846, 0.8888461538461538, 0.9082692307692307, 0.8621153846153846, 0.9034615384615384, 0.884423076923077, 0.8696153846153846, 0.8173076923076923]
2022-01-23 21:17:56:INFO:Loss = [0.6300872025915921, 0.5467139526867518, 0.4887095987302858, 0.31251931183858406, 0.3528009087354943, 0.5126239833103822, 0.4424318962785317, 0.4346383012809663, 0.5117758639087417, 0.6631503605589947]
2022-01-23 21:17:56:INFO:-------------Training local models-------------
2022-01-23 21:22:06:INFO:-------------Aggregating local models-------------
2022-01-23 21:22:08:INFO:-------------Round number: 32-------------
2022-01-23 21:22:08:INFO:-------------Sending models-------------
2022-01-23 21:22:08:INFO:-------------Evaluating models-------------
2022-01-23 21:22:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:22:09:INFO:Accuracy = [0.8653846153846154, 0.8217307692307693, 0.8584615384615385, 0.8896153846153846, 0.9086538461538461, 0.8626923076923076, 0.9040384615384616, 0.8840384615384616, 0.8696153846153846, 0.8167307692307693]
2022-01-23 21:22:09:INFO:Loss = [0.6331761342197961, 0.5519831212605613, 0.48947504027966293, 0.31428775645354806, 0.35505604681692116, 0.5162064617914159, 0.4444662095579238, 0.43853052583919916, 0.5140362603878412, 0.6662198706261944]
2022-01-23 21:22:09:INFO:-------------Training local models-------------
2022-01-23 21:26:19:INFO:-------------Aggregating local models-------------
2022-01-23 21:26:21:INFO:-------------Round number: 33-------------
2022-01-23 21:26:21:INFO:-------------Sending models-------------
2022-01-23 21:26:21:INFO:-------------Evaluating models-------------
2022-01-23 21:26:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:26:21:INFO:Accuracy = [0.8651923076923077, 0.8213461538461538, 0.8596153846153847, 0.8896153846153846, 0.9086538461538461, 0.8632692307692308, 0.9038461538461539, 0.8836538461538461, 0.869423076923077, 0.8165384615384615]
2022-01-23 21:26:21:INFO:Loss = [0.6365454609930077, 0.5566930620538048, 0.49040966425043453, 0.3161959677116521, 0.357063752247296, 0.5196140303795311, 0.4464127274057738, 0.44237334595471534, 0.5162892714670306, 0.6689274504396263]
2022-01-23 21:26:21:INFO:-------------Training local models-------------
2022-01-23 21:30:31:INFO:-------------Aggregating local models-------------
2022-01-23 21:30:34:INFO:-------------Round number: 34-------------
2022-01-23 21:30:34:INFO:-------------Sending models-------------
2022-01-23 21:30:34:INFO:-------------Evaluating models-------------
2022-01-23 21:30:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:30:34:INFO:Accuracy = [0.865, 0.8209615384615384, 0.8601923076923077, 0.8898076923076923, 0.9094230769230769, 0.8636538461538461, 0.9038461538461539, 0.8834615384615384, 0.8696153846153846, 0.8161538461538461]
2022-01-23 21:30:34:INFO:Loss = [0.639460342880109, 0.561521292154094, 0.4915902363231558, 0.31811058256859653, 0.35907467961806105, 0.5229873419399994, 0.44819187111883924, 0.4462067996067232, 0.5185249387687481, 0.6715248969309099]
2022-01-23 21:30:34:INFO:-------------Training local models-------------
2022-01-23 21:34:44:INFO:-------------Aggregating local models-------------
2022-01-23 21:34:46:INFO:-------------Round number: 35-------------
2022-01-23 21:34:46:INFO:-------------Sending models-------------
2022-01-23 21:34:46:INFO:-------------Evaluating models-------------
2022-01-23 21:34:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:34:47:INFO:Accuracy = [0.8648076923076923, 0.8205769230769231, 0.8605769230769231, 0.8915384615384615, 0.9094230769230769, 0.8634615384615385, 0.9032692307692308, 0.8825, 0.8698076923076923, 0.8157692307692308]
2022-01-23 21:34:47:INFO:Loss = [0.6424411968628891, 0.5662051053781257, 0.49274790060385737, 0.320049624910028, 0.36059295673140485, 0.5260259437160969, 0.44986513331297406, 0.4500199348776033, 0.5207263126769528, 0.6739141056613545]
2022-01-23 21:34:47:INFO:-------------Training local models-------------
2022-01-23 21:38:56:INFO:-------------Aggregating local models-------------
2022-01-23 21:38:59:INFO:-------------Round number: 36-------------
2022-01-23 21:38:59:INFO:-------------Sending models-------------
2022-01-23 21:38:59:INFO:-------------Evaluating models-------------
2022-01-23 21:38:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:38:59:INFO:Accuracy = [0.864423076923077, 0.8205769230769231, 0.8605769230769231, 0.8919230769230769, 0.9096153846153846, 0.8634615384615385, 0.9030769230769231, 0.8821153846153846, 0.8698076923076923, 0.8153846153846154]
2022-01-23 21:38:59:INFO:Loss = [0.6453598616401975, 0.5711420814306201, 0.49417967471366026, 0.3221314962672925, 0.3621848805123591, 0.5291864332358762, 0.4516665166243351, 0.45380913592236116, 0.5229548575003858, 0.6761507459800319]
2022-01-23 21:38:59:INFO:-------------Training local models-------------
2022-01-23 21:43:09:INFO:-------------Aggregating local models-------------
2022-01-23 21:43:11:INFO:-------------Round number: 37-------------
2022-01-23 21:43:11:INFO:-------------Sending models-------------
2022-01-23 21:43:12:INFO:-------------Evaluating models-------------
2022-01-23 21:43:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:43:12:INFO:Accuracy = [0.8642307692307692, 0.8196153846153846, 0.8605769230769231, 0.8919230769230769, 0.9098076923076923, 0.8636538461538461, 0.9030769230769231, 0.8819230769230769, 0.87, 0.8144230769230769]
2022-01-23 21:43:12:INFO:Loss = [0.648016952415044, 0.5757822211383498, 0.49550957046358235, 0.32434228875046334, 0.36354066231741367, 0.5316240325880874, 0.453439242193641, 0.457475870372526, 0.5250579378364889, 0.6783350901135307]
2022-01-23 21:43:12:INFO:-------------Training local models-------------
2022-01-23 21:47:21:INFO:-------------Aggregating local models-------------
2022-01-23 21:47:24:INFO:-------------Round number: 38-------------
2022-01-23 21:47:24:INFO:-------------Sending models-------------
2022-01-23 21:47:24:INFO:-------------Evaluating models-------------
2022-01-23 21:47:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:47:24:INFO:Accuracy = [0.8640384615384615, 0.8198076923076923, 0.8607692307692307, 0.8909615384615385, 0.91, 0.8648076923076923, 0.9026923076923077, 0.8815384615384615, 0.87, 0.8140384615384615]
2022-01-23 21:47:24:INFO:Loss = [0.6505904101252151, 0.5800332753850364, 0.49692786091922103, 0.3265989064988949, 0.36456998173106026, 0.5344334755708797, 0.45495757630068023, 0.4611596153659915, 0.5270591536197501, 0.6804722356067102]
2022-01-23 21:47:24:INFO:-------------Training local models-------------
2022-01-23 21:51:34:INFO:-------------Aggregating local models-------------
2022-01-23 21:51:36:INFO:-------------Round number: 39-------------
2022-01-23 21:51:36:INFO:-------------Sending models-------------
2022-01-23 21:51:36:INFO:-------------Evaluating models-------------
2022-01-23 21:51:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:51:37:INFO:Accuracy = [0.8648076923076923, 0.8201923076923077, 0.8611538461538462, 0.8907692307692308, 0.9101923076923077, 0.864423076923077, 0.9025, 0.8817307692307692, 0.8703846153846154, 0.8140384615384615]
2022-01-23 21:51:37:INFO:Loss = [0.6536598833087667, 0.5836823332075745, 0.4985258418464582, 0.3288807838122151, 0.3680163601823621, 0.5369007405135842, 0.45646353726820404, 0.46489178658563246, 0.5292408389290918, 0.6827585448325129]
2022-01-23 21:51:37:INFO:-------------Training local models-------------
2022-01-23 21:55:46:INFO:-------------Aggregating local models-------------
2022-01-23 21:55:49:INFO:-------------Round number: 40-------------
2022-01-23 21:55:49:INFO:-------------Sending models-------------
2022-01-23 21:55:49:INFO:-------------Evaluating models-------------
2022-01-23 21:55:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:55:49:INFO:Accuracy = [0.865, 0.8201923076923077, 0.8609615384615384, 0.89, 0.91, 0.864423076923077, 0.9025, 0.8821153846153846, 0.87, 0.8138461538461539]
2022-01-23 21:55:49:INFO:Loss = [0.656284978972298, 0.5874336851370922, 0.5002918086063521, 0.33121602279998813, 0.36899538212646105, 0.5393140102072581, 0.45794605304875474, 0.4685835171512036, 0.5313872168669079, 0.6849485064922192]
2022-01-23 21:55:49:INFO:-------------Training local models-------------
2022-01-23 21:59:59:INFO:-------------Aggregating local models-------------
2022-01-23 22:00:01:INFO:-------------Round number: 41-------------
2022-01-23 22:00:01:INFO:-------------Sending models-------------
2022-01-23 22:00:02:INFO:-------------Evaluating models-------------
2022-01-23 22:00:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:00:02:INFO:Accuracy = [0.8651923076923077, 0.8203846153846154, 0.8613461538461539, 0.8903846153846153, 0.9101923076923077, 0.8646153846153846, 0.9025, 0.8817307692307692, 0.8701923076923077, 0.8132692307692307]
2022-01-23 22:00:02:INFO:Loss = [0.6590486938755651, 0.5913189774507303, 0.502090424592867, 0.33364640793843137, 0.37021213127613567, 0.5418296354486162, 0.4595379719525786, 0.47240624731057324, 0.533555051260639, 0.6872506905640946]
2022-01-23 22:00:02:INFO:-------------Training local models-------------
2022-01-23 22:04:12:INFO:-------------Aggregating local models-------------
2022-01-23 22:04:14:INFO:-------------Round number: 42-------------
2022-01-23 22:04:14:INFO:-------------Sending models-------------
2022-01-23 22:04:14:INFO:-------------Evaluating models-------------
2022-01-23 22:04:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:04:14:INFO:Accuracy = [0.8651923076923077, 0.8205769230769231, 0.8609615384615384, 0.8907692307692308, 0.9107692307692308, 0.8646153846153846, 0.9023076923076923, 0.8817307692307692, 0.8703846153846154, 0.8134615384615385]
2022-01-23 22:04:14:INFO:Loss = [0.6617368785970169, 0.5950727844598916, 0.5038704861243997, 0.3361726511480251, 0.3756532386091399, 0.5443789402530596, 0.4609276070788418, 0.47615046550610995, 0.5356184738259869, 0.6892730342935045]
2022-01-23 22:04:14:INFO:-------------Training local models-------------
2022-01-23 22:08:24:INFO:-------------Aggregating local models-------------
2022-01-23 22:08:26:INFO:-------------Round number: 43-------------
2022-01-23 22:08:26:INFO:-------------Sending models-------------
2022-01-23 22:08:26:INFO:-------------Evaluating models-------------
2022-01-23 22:08:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:08:27:INFO:Accuracy = [0.864423076923077, 0.8201923076923077, 0.8607692307692307, 0.890576923076923, 0.9111538461538462, 0.8651923076923077, 0.9025, 0.8815384615384615, 0.8707692307692307, 0.8132692307692307]
2022-01-23 22:08:27:INFO:Loss = [0.6641298911920155, 0.5986730707456724, 0.505540295357325, 0.33875188787799115, 0.37646766136934345, 0.5464553876980133, 0.46219909232016876, 0.47992852373387834, 0.5374810404797384, 0.6911011605255996]
2022-01-23 22:08:27:INFO:-------------Training local models-------------
2022-01-23 22:12:36:INFO:-------------Aggregating local models-------------
2022-01-23 22:12:39:INFO:-------------Round number: 44-------------
2022-01-23 22:12:39:INFO:-------------Sending models-------------
2022-01-23 22:12:39:INFO:-------------Evaluating models-------------
2022-01-23 22:12:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:12:39:INFO:Accuracy = [0.8642307692307692, 0.8205769230769231, 0.8607692307692307, 0.8909615384615385, 0.9115384615384615, 0.8657692307692307, 0.9025, 0.8821153846153846, 0.8701923076923077, 0.8132692307692307]
2022-01-23 22:12:39:INFO:Loss = [0.6664244964926044, 0.6023964424959838, 0.5072565957235173, 0.3412809024004953, 0.37741193724650657, 0.5482396478138211, 0.4634913205372868, 0.48372067782656814, 0.5392302107156866, 0.6928808772720983]
2022-01-23 22:12:39:INFO:-------------Training local models-------------
2022-01-23 22:16:49:INFO:-------------Aggregating local models-------------
2022-01-23 22:16:51:INFO:-------------Round number: 45-------------
2022-01-23 22:16:51:INFO:-------------Sending models-------------
2022-01-23 22:16:52:INFO:-------------Evaluating models-------------
2022-01-23 22:16:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:16:52:INFO:Accuracy = [0.8636538461538461, 0.8203846153846154, 0.8613461538461539, 0.8911538461538462, 0.9115384615384615, 0.865576923076923, 0.9025, 0.8821153846153846, 0.8701923076923077, 0.813076923076923]
2022-01-23 22:16:52:INFO:Loss = [0.6685284067902663, 0.6062338583290582, 0.5091790500287411, 0.3439240851034461, 0.37846178996551316, 0.5502338390517182, 0.4648361635081528, 0.48731996470877886, 0.5410103578321398, 0.6946267160553992]
2022-01-23 22:16:52:INFO:-------------Training local models-------------
2022-01-23 22:21:02:INFO:-------------Aggregating local models-------------
2022-01-23 22:21:04:INFO:-------------Round number: 46-------------
2022-01-23 22:21:04:INFO:-------------Sending models-------------
2022-01-23 22:21:04:INFO:-------------Evaluating models-------------
2022-01-23 22:21:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:21:05:INFO:Accuracy = [0.8636538461538461, 0.8207692307692308, 0.8613461538461539, 0.8913461538461539, 0.911923076923077, 0.8657692307692307, 0.9023076923076923, 0.8817307692307692, 0.8703846153846154, 0.8125]
2022-01-23 22:21:05:INFO:Loss = [0.670823283822616, 0.6099557782253424, 0.5111406468521147, 0.3466256204055054, 0.37930993138741964, 0.5521427269301896, 0.4662123009696258, 0.4909606329808342, 0.5427042039450148, 0.6963793565264496]
2022-01-23 22:21:05:INFO:-------------Training local models-------------
2022-01-23 22:25:14:INFO:-------------Aggregating local models-------------
2022-01-23 22:25:16:INFO:-------------Round number: 47-------------
2022-01-23 22:25:16:INFO:-------------Sending models-------------
2022-01-23 22:25:16:INFO:-------------Evaluating models-------------
2022-01-23 22:25:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:25:17:INFO:Accuracy = [0.8636538461538461, 0.8209615384615384, 0.8617307692307692, 0.8913461538461539, 0.9121153846153847, 0.8671153846153846, 0.9021153846153847, 0.8813461538461539, 0.870576923076923, 0.8125]
2022-01-23 22:25:17:INFO:Loss = [0.6730873607538552, 0.6136504124299861, 0.5130750266586381, 0.34935980519304183, 0.38042499984770145, 0.5535058622819913, 0.4674982243206894, 0.49456346194689943, 0.5443180218667644, 0.6983591422554477]
2022-01-23 22:25:17:INFO:-------------Training local models-------------
2022-01-23 22:29:27:INFO:-------------Aggregating local models-------------
2022-01-23 22:29:29:INFO:-------------Round number: 48-------------
2022-01-23 22:29:29:INFO:-------------Sending models-------------
2022-01-23 22:29:29:INFO:-------------Evaluating models-------------
2022-01-23 22:29:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:29:29:INFO:Accuracy = [0.8634615384615385, 0.8213461538461538, 0.8621153846153846, 0.8913461538461539, 0.9123076923076923, 0.8667307692307692, 0.9023076923076923, 0.8811538461538462, 0.870576923076923, 0.8115384615384615]
2022-01-23 22:29:29:INFO:Loss = [0.6753542955024247, 0.6171451915605268, 0.515080288201786, 0.3520837843189628, 0.3813599645053238, 0.5549736525533192, 0.4686270385620726, 0.49805987207358926, 0.5458502952087656, 0.7003599334896605]
2022-01-23 22:29:29:INFO:-------------Training local models-------------
2022-01-23 22:33:39:INFO:-------------Aggregating local models-------------
2022-01-23 22:33:42:INFO:-------------Round number: 49-------------
2022-01-23 22:33:42:INFO:-------------Sending models-------------
2022-01-23 22:33:42:INFO:-------------Evaluating models-------------
2022-01-23 22:33:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:33:42:INFO:Accuracy = [0.8634615384615385, 0.8209615384615384, 0.8623076923076923, 0.8915384615384615, 0.9121153846153847, 0.8673076923076923, 0.9023076923076923, 0.8807692307692307, 0.8703846153846154, 0.8113461538461538]
2022-01-23 22:33:42:INFO:Loss = [0.6773140756933851, 0.6210325931153, 0.5171521102285553, 0.3548491837103099, 0.38224574286924995, 0.5585833863153942, 0.46966242061423075, 0.5012520693471043, 0.5475949425198661, 0.7024272632276664]
2022-01-23 22:33:42:INFO:-------------Training local models-------------
2022-01-23 22:37:52:INFO:-------------Aggregating local models-------------
2022-01-23 22:37:54:INFO:-------------Round number: 50-------------
2022-01-23 22:37:54:INFO:-------------Sending models-------------
2022-01-23 22:37:54:INFO:-------------Evaluating models-------------
2022-01-23 22:37:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:37:55:INFO:Accuracy = [0.8634615384615385, 0.8207692307692308, 0.8625, 0.8913461538461539, 0.9117307692307692, 0.8675, 0.9021153846153847, 0.8809615384615385, 0.8703846153846154, 0.8115384615384615]
2022-01-23 22:37:55:INFO:Loss = [0.6791638855091571, 0.6247993130437652, 0.5190807902913898, 0.35754027031795815, 0.3831223308852014, 0.5600519450883369, 0.472948469493321, 0.5045593621490088, 0.5492242326123372, 0.7044553882296896]
2022-01-23 22:37:55:INFO:-------------Training local models-------------
2022-01-23 22:42:04:INFO:-------------Aggregating local models-------------
2022-01-23 22:42:06:INFO:-------------Round number: 51-------------
2022-01-23 22:42:06:INFO:-------------Sending models-------------
2022-01-23 22:42:06:INFO:-------------Evaluating models-------------
2022-01-23 22:42:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:42:07:INFO:Accuracy = [0.8636538461538461, 0.8203846153846154, 0.8628846153846154, 0.8907692307692308, 0.9117307692307692, 0.8669230769230769, 0.9021153846153847, 0.8809615384615385, 0.870576923076923, 0.8115384615384615]
2022-01-23 22:42:07:INFO:Loss = [0.681214527861392, 0.6286487941048248, 0.5211236557102333, 0.36038533091686986, 0.3839353733531495, 0.5614067714150923, 0.47393670005896216, 0.5078549288855356, 0.5507951589668385, 0.7064107278253616]
2022-01-23 22:42:07:INFO:-------------Training local models-------------
2022-01-23 22:46:16:INFO:-------------Aggregating local models-------------
2022-01-23 22:46:19:INFO:-------------Round number: 52-------------
2022-01-23 22:46:19:INFO:-------------Sending models-------------
2022-01-23 22:46:19:INFO:-------------Evaluating models-------------
2022-01-23 22:46:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:46:19:INFO:Accuracy = [0.8640384615384615, 0.82, 0.8630769230769231, 0.8903846153846153, 0.9117307692307692, 0.8665384615384616, 0.9021153846153847, 0.8811538461538462, 0.870576923076923, 0.8121153846153846]
2022-01-23 22:46:19:INFO:Loss = [0.6832172457213276, 0.6323493819801954, 0.5231203771129282, 0.36315396264637034, 0.38710084539931044, 0.5630516031263212, 0.4749645252441741, 0.5111771118315398, 0.5523635805555807, 0.7083105949571361]
2022-01-23 22:46:19:INFO:-------------Training local models-------------
2022-01-23 22:50:29:INFO:-------------Aggregating local models-------------
2022-01-23 22:50:31:INFO:-------------Round number: 53-------------
2022-01-23 22:50:31:INFO:-------------Sending models-------------
2022-01-23 22:50:32:INFO:-------------Evaluating models-------------
2022-01-23 22:50:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:50:32:INFO:Accuracy = [0.8636538461538461, 0.82, 0.8630769230769231, 0.890576923076923, 0.9115384615384615, 0.8673076923076923, 0.9021153846153847, 0.8809615384615385, 0.870576923076923, 0.8126923076923077]
2022-01-23 22:50:32:INFO:Loss = [0.6851296544670661, 0.63592328545855, 0.5251873962453758, 0.3658550016902714, 0.38797820853897763, 0.5648455084414169, 0.47589748669578025, 0.5144848356759701, 0.5537709382383932, 0.7103001747808986]
2022-01-23 22:50:32:INFO:-------------Training local models-------------
2022-01-23 22:54:42:INFO:-------------Aggregating local models-------------
2022-01-23 22:54:44:INFO:-------------Round number: 54-------------
2022-01-23 22:54:44:INFO:-------------Sending models-------------
2022-01-23 22:54:44:INFO:-------------Evaluating models-------------
2022-01-23 22:54:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:54:45:INFO:Accuracy = [0.8636538461538461, 0.82, 0.8634615384615385, 0.8913461538461539, 0.9115384615384615, 0.8673076923076923, 0.9021153846153847, 0.8807692307692307, 0.870576923076923, 0.8111538461538461]
2022-01-23 22:54:45:INFO:Loss = [0.6870776456706573, 0.6393894162848622, 0.5272712063114551, 0.36854455636974026, 0.38878219668773595, 0.5684857662579537, 0.4768331808842889, 0.5175458379497356, 0.5551413793602058, 0.712250792353818]
2022-01-23 22:54:45:INFO:-------------Training local models-------------
2022-01-23 22:58:54:INFO:-------------Aggregating local models-------------
2022-01-23 22:58:56:INFO:-------------Round number: 55-------------
2022-01-23 22:58:56:INFO:-------------Sending models-------------
2022-01-23 22:58:57:INFO:-------------Evaluating models-------------
2022-01-23 22:58:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:58:57:INFO:Accuracy = [0.8634615384615385, 0.82, 0.8634615384615385, 0.8915384615384615, 0.9115384615384615, 0.8675, 0.9021153846153847, 0.880576923076923, 0.870576923076923, 0.8115384615384615]
2022-01-23 22:58:57:INFO:Loss = [0.6889348344216509, 0.642821601153453, 0.5292749990657145, 0.3712449488255935, 0.39179037809662987, 0.5702340869609613, 0.4777387382432957, 0.5206146546882408, 0.5565807448356631, 0.7143607400455669]
2022-01-23 22:58:57:INFO:-------------Training local models-------------
2022-01-23 23:03:06:INFO:-------------Aggregating local models-------------
2022-01-23 23:03:09:INFO:-------------Round number: 56-------------
2022-01-23 23:03:09:INFO:-------------Sending models-------------
2022-01-23 23:03:09:INFO:-------------Evaluating models-------------
2022-01-23 23:03:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 23:03:09:INFO:Accuracy = [0.8634615384615385, 0.8198076923076923, 0.864423076923077, 0.8917307692307692, 0.9117307692307692, 0.8676923076923077, 0.9021153846153847, 0.8801923076923077, 0.8707692307692307, 0.8113461538461538]
2022-01-23 23:03:09:INFO:Loss = [0.6905148265451106, 0.6462556990409561, 0.5313780832838557, 0.37392295047976193, 0.3925654590479658, 0.5717653878523029, 0.4786413711464355, 0.5235760653696301, 0.5580063864653172, 0.7164384170456077]
2022-01-23 23:03:09:INFO:-------------Training local models-------------
2022-01-23 23:07:19:INFO:-------------Aggregating local models-------------
2022-01-23 23:07:22:INFO:-------------Round number: 57-------------
2022-01-23 23:07:22:INFO:-------------Sending models-------------
2022-01-23 23:07:22:INFO:-------------Evaluating models-------------
2022-01-23 23:07:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 23:07:22:INFO:Accuracy = [0.8634615384615385, 0.8196153846153846, 0.8642307692307692, 0.8907692307692308, 0.9117307692307692, 0.8676923076923077, 0.9021153846153847, 0.88, 0.870576923076923, 0.8115384615384615]
2022-01-23 23:07:22:INFO:Loss = [0.6922932196962742, 0.6498643873670656, 0.5333618179509079, 0.3766798627638519, 0.39550291250662456, 0.5728841284494592, 0.47947273175640687, 0.5265849001975067, 0.5593056437634844, 0.7185882977516415]
2022-01-23 23:07:22:INFO:-------------Training local models-------------
2022-01-23 23:11:31:INFO:-------------Aggregating local models-------------
2022-01-23 23:11:34:INFO:-------------Round number: 58-------------
2022-01-23 23:11:34:INFO:-------------Sending models-------------
2022-01-23 23:11:34:INFO:-------------Evaluating models-------------
2022-01-23 23:11:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 23:11:34:INFO:Accuracy = [0.8634615384615385, 0.8194230769230769, 0.8638461538461538, 0.8901923076923077, 0.9117307692307692, 0.8678846153846154, 0.9021153846153847, 0.88, 0.8707692307692307, 0.8105769230769231]
2022-01-23 23:11:34:INFO:Loss = [0.6941500192273312, 0.6532494375116514, 0.5353946034118823, 0.3794733159323606, 0.3961423577221957, 0.5738891122849824, 0.48038067259739575, 0.5295783423657667, 0.5605804239917234, 0.7207027171008611]
2022-01-23 23:11:34:INFO:-------------Training local models-------------
2022-01-23 23:15:44:INFO:-------------Aggregating local models-------------
2022-01-23 23:15:46:INFO:-------------Round number: 59-------------
2022-01-23 23:15:46:INFO:-------------Sending models-------------
2022-01-23 23:15:47:INFO:-------------Evaluating models-------------
2022-01-23 23:15:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 23:15:47:INFO:Accuracy = [0.8634615384615385, 0.8192307692307692, 0.8636538461538461, 0.8901923076923077, 0.9117307692307692, 0.8676923076923077, 0.9019230769230769, 0.8798076923076923, 0.8711538461538462, 0.8101923076923077]
2022-01-23 23:15:47:INFO:Loss = [0.6955753269303736, 0.6566071830269931, 0.537242363567342, 0.3821510500498474, 0.3968289083733488, 0.5750199947945895, 0.48118625261066394, 0.5323830944398651, 0.5618587665020851, 0.7226916649149364]
2022-01-23 23:15:47:INFO:-------------Training local models-------------
2022-01-23 23:19:57:INFO:-------------Aggregating local models-------------
