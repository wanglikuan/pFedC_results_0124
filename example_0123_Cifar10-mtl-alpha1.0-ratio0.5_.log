2022-01-23 19:07:59:INFO:-------------Round number: 0-------------
2022-01-23 19:07:59:INFO:-------------Sending models-------------
2022-01-23 19:07:59:INFO:-------------Evaluating models-------------
2022-01-23 19:07:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:07:59:INFO:Accuracy = [0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.10050251256281408, 0.8992964824120603, 0.10050251256281408, 0.9045226130653267, 0.10060301507537689, 0.8994974874371859, 0.2986934673366834]
2022-01-23 19:07:59:INFO:Loss = [0.6629893836663596, 0.6195840658854, 0.6740921454213972, 0.7171490021686459, 0.6775418214462511, 0.7549932958492681, 0.6251682417476596, 0.704276480866437, 0.6679736396775173, 0.6946858889493511]
2022-01-23 19:07:59:INFO:-------------Training local models-------------
2022-01-23 19:10:06:INFO:-------------Aggregating local models-------------
2022-01-23 19:10:07:INFO:-------------Round number: 1-------------
2022-01-23 19:10:07:INFO:-------------Sending models-------------
2022-01-23 19:10:07:INFO:-------------Evaluating models-------------
2022-01-23 19:10:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:10:07:INFO:Accuracy = [0.8994974874371859, 0.8987939698492462, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9045226130653267, 0.8994974874371859, 0.869748743718593, 0.8716582914572865]
2022-01-23 19:10:07:INFO:Loss = [0.3715430917452328, 0.3949910033887355, 0.3516840272812388, 0.37450639626488613, 0.3412336004738832, 0.3515013628569081, 0.33351224780681743, 0.36135229393465434, 0.381540823671686, 0.3968565992674037]
2022-01-23 19:10:07:INFO:-------------Training local models-------------
2022-01-23 19:12:14:INFO:-------------Aggregating local models-------------
2022-01-23 19:12:15:INFO:-------------Round number: 2-------------
2022-01-23 19:12:15:INFO:-------------Sending models-------------
2022-01-23 19:12:15:INFO:-------------Evaluating models-------------
2022-01-23 19:12:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:12:15:INFO:Accuracy = [0.8994974874371859, 0.8981909547738693, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9045226130653267, 0.8994974874371859, 0.8768844221105527, 0.8759798994974874]
2022-01-23 19:12:15:INFO:Loss = [0.3636891510917913, 0.37754301629473813, 0.345718910646199, 0.36310199696813994, 0.34474619534147444, 0.36393444951455195, 0.3185865150661624, 0.3492571984104176, 0.3729852664111248, 0.37486621977096823]
2022-01-23 19:12:15:INFO:-------------Training local models-------------
2022-01-23 19:14:21:INFO:-------------Aggregating local models-------------
2022-01-23 19:14:22:INFO:-------------Round number: 3-------------
2022-01-23 19:14:22:INFO:-------------Sending models-------------
2022-01-23 19:14:23:INFO:-------------Evaluating models-------------
2022-01-23 19:14:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:14:23:INFO:Accuracy = [0.8994974874371859, 0.8964824120603015, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8992964824120603, 0.9045226130653267, 0.8994974874371859, 0.8801005025125628, 0.8809045226130653]
2022-01-23 19:14:23:INFO:Loss = [0.366585722221202, 0.37498208700712005, 0.3551640841529597, 0.37507140576539927, 0.35398889381681853, 0.37135472399505537, 0.32288558528426303, 0.35676998978284136, 0.37340198210136377, 0.3765618230529766]
2022-01-23 19:14:23:INFO:-------------Training local models-------------
2022-01-23 19:16:29:INFO:-------------Aggregating local models-------------
2022-01-23 19:16:30:INFO:-------------Round number: 4-------------
2022-01-23 19:16:30:INFO:-------------Sending models-------------
2022-01-23 19:16:30:INFO:-------------Evaluating models-------------
2022-01-23 19:16:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:16:31:INFO:Accuracy = [0.8994974874371859, 0.8950753768844221, 0.8994974874371859, 0.8994974874371859, 0.8993969849246232, 0.8992964824120603, 0.9045226130653267, 0.8994974874371859, 0.88321608040201, 0.8836180904522613]
2022-01-23 19:16:31:INFO:Loss = [0.3665530239816886, 0.3729952573776245, 0.3609520393100815, 0.38238906246333865, 0.3588514083893455, 0.37397972288443215, 0.32488064295214475, 0.3606947661943771, 0.37111142412501963, 0.37621851108182014]
2022-01-23 19:16:31:INFO:-------------Training local models-------------
2022-01-23 19:18:37:INFO:-------------Aggregating local models-------------
2022-01-23 19:18:38:INFO:-------------Round number: 5-------------
2022-01-23 19:18:38:INFO:-------------Sending models-------------
2022-01-23 19:18:38:INFO:-------------Evaluating models-------------
2022-01-23 19:18:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:18:38:INFO:Accuracy = [0.8975879396984925, 0.8937688442211055, 0.8994974874371859, 0.8992964824120603, 0.8989949748743719, 0.8987939698492462, 0.9045226130653267, 0.8994974874371859, 0.8861306532663317, 0.8862311557788944]
2022-01-23 19:18:38:INFO:Loss = [0.36545678538892734, 0.3713559235759716, 0.36456936253375144, 0.3866033152719239, 0.36130989975665684, 0.37474591004189534, 0.32515169146597084, 0.36260890930741274, 0.3676382710586241, 0.37431337995145786]
2022-01-23 19:18:38:INFO:-------------Training local models-------------
2022-01-23 19:20:45:INFO:-------------Aggregating local models-------------
2022-01-23 19:20:46:INFO:-------------Round number: 6-------------
2022-01-23 19:20:46:INFO:-------------Sending models-------------
2022-01-23 19:20:46:INFO:-------------Evaluating models-------------
2022-01-23 19:20:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:20:46:INFO:Accuracy = [0.8966834170854271, 0.8931658291457286, 0.8994974874371859, 0.8986934673366834, 0.8991959798994975, 0.8981909547738693, 0.9045226130653267, 0.8994974874371859, 0.8881407035175879, 0.8884422110552764]
2022-01-23 19:20:46:INFO:Loss = [0.36392658499617075, 0.36999738126543896, 0.36704621467758064, 0.38905725062792024, 0.3625380581048266, 0.3745639157954173, 0.32450472506409017, 0.36353587475254306, 0.36351913363490274, 0.371637599552097]
2022-01-23 19:20:46:INFO:-------------Training local models-------------
2022-01-23 19:22:53:INFO:-------------Aggregating local models-------------
2022-01-23 19:22:54:INFO:-------------Round number: 7-------------
2022-01-23 19:22:54:INFO:-------------Sending models-------------
2022-01-23 19:22:54:INFO:-------------Evaluating models-------------
2022-01-23 19:22:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:22:54:INFO:Accuracy = [0.8937688442211055, 0.8926633165829145, 0.8994974874371859, 0.8980904522613066, 0.8989949748743719, 0.8978894472361809, 0.9045226130653267, 0.8994974874371859, 0.8895477386934674, 0.8890452261306533]
2022-01-23 19:22:54:INFO:Loss = [0.3623181458693653, 0.36880955594268877, 0.3688347219821796, 0.3904923980859057, 0.36308781345885005, 0.37393868748267095, 0.32334641031172107, 0.36393691621833113, 0.35901104849786614, 0.3686565335971027]
2022-01-23 19:22:54:INFO:-------------Training local models-------------
2022-01-23 19:25:00:INFO:-------------Aggregating local models-------------
2022-01-23 19:25:01:INFO:-------------Round number: 8-------------
2022-01-23 19:25:01:INFO:-------------Sending models-------------
2022-01-23 19:25:02:INFO:-------------Evaluating models-------------
2022-01-23 19:25:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:25:02:INFO:Accuracy = [0.8921608040201005, 0.8921608040201005, 0.8994974874371859, 0.8972864321608041, 0.8990954773869346, 0.8978894472361809, 0.9045226130653267, 0.8993969849246232, 0.8925628140703518, 0.8900502512562815]
2022-01-23 19:25:02:INFO:Loss = [0.3607440048725761, 0.36757362068597993, 0.3702195276267565, 0.39138486681871076, 0.36330198927141316, 0.3731881829362419, 0.32204472662029254, 0.3638952426874458, 0.35440488451689334, 0.3656793395478522]
2022-01-23 19:25:02:INFO:-------------Training local models-------------
2022-01-23 19:27:08:INFO:-------------Aggregating local models-------------
2022-01-23 19:27:09:INFO:-------------Round number: 9-------------
2022-01-23 19:27:09:INFO:-------------Sending models-------------
2022-01-23 19:27:09:INFO:-------------Evaluating models-------------
2022-01-23 19:27:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:27:09:INFO:Accuracy = [0.8910552763819095, 0.8921608040201005, 0.8994974874371859, 0.8963819095477387, 0.8986934673366834, 0.8975879396984925, 0.9045226130653267, 0.8994974874371859, 0.8939698492462311, 0.8894472361809045]
2022-01-23 19:27:09:INFO:Loss = [0.3592636502867368, 0.36625366324755415, 0.37127312703348286, 0.39197056961418997, 0.363348881353685, 0.372561063299227, 0.32068238970378987, 0.36345128318173203, 0.35006237239693877, 0.36287608368312896]
2022-01-23 19:27:09:INFO:-------------Training local models-------------
2022-01-23 19:29:16:INFO:-------------Aggregating local models-------------
2022-01-23 19:29:17:INFO:-------------Round number: 10-------------
2022-01-23 19:29:17:INFO:-------------Sending models-------------
2022-01-23 19:29:17:INFO:-------------Evaluating models-------------
2022-01-23 19:29:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:29:17:INFO:Accuracy = [0.8894472361809045, 0.8914572864321608, 0.8994974874371859, 0.8959798994974875, 0.8989949748743719, 0.8968844221105527, 0.9044221105527638, 0.8995979899497487, 0.8947738693467336, 0.890251256281407]
2022-01-23 19:29:17:INFO:Loss = [0.3579962183183162, 0.3647907198074475, 0.37207732203617766, 0.39234985733152034, 0.36326289686126323, 0.37209667527495915, 0.31936067467012524, 0.36256764417317644, 0.3460758328437805, 0.3603041246907795]
2022-01-23 19:29:17:INFO:-------------Training local models-------------
2022-01-23 19:31:23:INFO:-------------Aggregating local models-------------
2022-01-23 19:31:24:INFO:-------------Round number: 11-------------
2022-01-23 19:31:24:INFO:-------------Sending models-------------
2022-01-23 19:31:25:INFO:-------------Evaluating models-------------
2022-01-23 19:31:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:31:25:INFO:Accuracy = [0.8884422110552764, 0.8906532663316583, 0.8994974874371859, 0.8942713567839196, 0.8985929648241207, 0.8969849246231156, 0.904321608040201, 0.8994974874371859, 0.895175879396985, 0.8906532663316583]
2022-01-23 19:31:25:INFO:Loss = [0.3571092068549976, 0.3631900423136189, 0.3727173899585877, 0.3925248077466859, 0.36307435329235976, 0.37169933423924084, 0.3180865128934103, 0.3613273005689209, 0.3424363489726081, 0.35798983043761706]
2022-01-23 19:31:25:INFO:-------------Training local models-------------
2022-01-23 19:33:31:INFO:-------------Aggregating local models-------------
2022-01-23 19:33:32:INFO:-------------Round number: 12-------------
2022-01-23 19:33:32:INFO:-------------Sending models-------------
2022-01-23 19:33:32:INFO:-------------Evaluating models-------------
2022-01-23 19:33:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:33:32:INFO:Accuracy = [0.8872361809045226, 0.8907537688442211, 0.8994974874371859, 0.8936683417085427, 0.8986934673366834, 0.89678391959799, 0.9042211055276382, 0.8994974874371859, 0.8959798994974875, 0.8916582914572865]
2022-01-23 19:33:32:INFO:Loss = [0.3568491962686855, 0.36137497305271016, 0.37316015572404143, 0.392425827944099, 0.3627535664855535, 0.37132973587093643, 0.3169194202221949, 0.3598633956669563, 0.3389414683658274, 0.3559069867110133]
2022-01-23 19:33:32:INFO:-------------Training local models-------------
2022-01-23 19:35:39:INFO:-------------Aggregating local models-------------
2022-01-23 19:35:40:INFO:-------------Round number: 13-------------
2022-01-23 19:35:40:INFO:-------------Sending models-------------
2022-01-23 19:35:40:INFO:-------------Evaluating models-------------
2022-01-23 19:35:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:35:40:INFO:Accuracy = [0.8858291457286432, 0.8906532663316583, 0.8993969849246232, 0.892964824120603, 0.898391959798995, 0.8954773869346734, 0.9042211055276382, 0.8996984924623116, 0.8969849246231156, 0.892462311557789]
2022-01-23 19:35:40:INFO:Loss = [0.3572354536859234, 0.35934535238012, 0.3734891863923576, 0.39210947973644317, 0.36215318851734524, 0.37104738627246875, 0.31596282477743326, 0.35826189583869433, 0.33575339263408027, 0.3541236576722495]
2022-01-23 19:35:40:INFO:-------------Training local models-------------
2022-01-23 19:37:47:INFO:-------------Aggregating local models-------------
2022-01-23 19:37:48:INFO:-------------Round number: 14-------------
2022-01-23 19:37:48:INFO:-------------Sending models-------------
2022-01-23 19:37:48:INFO:-------------Evaluating models-------------
2022-01-23 19:37:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:37:48:INFO:Accuracy = [0.8838190954773869, 0.8895477386934674, 0.8992964824120603, 0.8920603015075377, 0.8985929648241207, 0.8946733668341709, 0.9038190954773869, 0.8993969849246232, 0.8975879396984925, 0.8917587939698493]
2022-01-23 19:37:48:INFO:Loss = [0.3579637240524867, 0.3572148450055913, 0.3737538885231593, 0.39169272990082976, 0.36122550796623804, 0.37085011885992847, 0.315176580981094, 0.35656813640690327, 0.33304904588502854, 0.3525531645396247]
2022-01-23 19:37:48:INFO:-------------Training local models-------------
2022-01-23 19:39:54:INFO:-------------Aggregating local models-------------
2022-01-23 19:39:55:INFO:-------------Round number: 15-------------
2022-01-23 19:39:55:INFO:-------------Sending models-------------
2022-01-23 19:39:56:INFO:-------------Evaluating models-------------
2022-01-23 19:39:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:39:56:INFO:Accuracy = [0.8821105527638191, 0.8882412060301508, 0.8991959798994975, 0.8912562814070352, 0.8987939698492462, 0.894572864321608, 0.9034170854271357, 0.8996984924623116, 0.8984924623115578, 0.8911557788944724]
2022-01-23 19:39:56:INFO:Loss = [0.35885085337725114, 0.35507321792032254, 0.37393108130100383, 0.39111070866560815, 0.36001919097636814, 0.37073365213283943, 0.31455136944502404, 0.35490083439865305, 0.330676023534794, 0.35105256294485315]
2022-01-23 19:39:56:INFO:-------------Training local models-------------
2022-01-23 19:42:02:INFO:-------------Aggregating local models-------------
2022-01-23 19:42:03:INFO:-------------Round number: 16-------------
2022-01-23 19:42:03:INFO:-------------Sending models-------------
2022-01-23 19:42:03:INFO:-------------Evaluating models-------------
2022-01-23 19:42:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:42:04:INFO:Accuracy = [0.8802010050251257, 0.8867336683417085, 0.8990954773869346, 0.8915577889447236, 0.898391959798995, 0.8938693467336684, 0.9031155778894472, 0.9001005025125628, 0.8981909547738693, 0.8909547738693467]
2022-01-23 19:42:04:INFO:Loss = [0.3600212248725508, 0.3530006345792032, 0.3740772414746596, 0.39060750334107097, 0.3588402395571896, 0.3707908937080422, 0.3139823868709275, 0.3531445444528781, 0.32877503792245183, 0.34976593199087747]
2022-01-23 19:42:04:INFO:-------------Training local models-------------
2022-01-23 19:44:10:INFO:-------------Aggregating local models-------------
2022-01-23 19:44:11:INFO:-------------Round number: 17-------------
2022-01-23 19:44:11:INFO:-------------Sending models-------------
2022-01-23 19:44:11:INFO:-------------Evaluating models-------------
2022-01-23 19:44:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:44:11:INFO:Accuracy = [0.8792964824120603, 0.8855276381909548, 0.8991959798994975, 0.8907537688442211, 0.8985929648241207, 0.8930653266331658, 0.9033165829145728, 0.8998994974874371, 0.8984924623115578, 0.8907537688442211]
2022-01-23 19:44:11:INFO:Loss = [0.36141014114097136, 0.3510776860031051, 0.3741531743476139, 0.39017385693650747, 0.35803614519349297, 0.3709639643304911, 0.31337045263452223, 0.35145368153725437, 0.3272752630051656, 0.3486978985256885]
2022-01-23 19:44:11:INFO:-------------Training local models-------------
2022-01-23 19:46:18:INFO:-------------Aggregating local models-------------
2022-01-23 19:46:19:INFO:-------------Round number: 18-------------
2022-01-23 19:46:19:INFO:-------------Sending models-------------
2022-01-23 19:46:19:INFO:-------------Evaluating models-------------
2022-01-23 19:46:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:46:19:INFO:Accuracy = [0.8782914572864322, 0.8836180904522613, 0.8991959798994975, 0.8904522613065327, 0.8984924623115578, 0.8927638190954774, 0.9034170854271357, 0.9, 0.8989949748743719, 0.8904522613065327]
2022-01-23 19:46:19:INFO:Loss = [0.36283002022522776, 0.3493627008780762, 0.37413283358866245, 0.38970641379979387, 0.35776174173283215, 0.37110493440723896, 0.3125332886974407, 0.3497791468498096, 0.32582023275557476, 0.34787100224039663]
2022-01-23 19:46:19:INFO:-------------Training local models-------------
2022-01-23 19:48:25:INFO:-------------Aggregating local models-------------
2022-01-23 19:48:26:INFO:-------------Round number: 19-------------
2022-01-23 19:48:26:INFO:-------------Sending models-------------
2022-01-23 19:48:26:INFO:-------------Evaluating models-------------
2022-01-23 19:48:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:48:27:INFO:Accuracy = [0.8773869346733668, 0.8829145728643216, 0.8990954773869346, 0.8904522613065327, 0.8982914572864321, 0.8915577889447236, 0.9034170854271357, 0.9004020100502512, 0.8993969849246232, 0.8898492462311558]
2022-01-23 19:48:27:INFO:Loss = [0.36431621247200513, 0.3478681419662495, 0.3740283168440488, 0.38927809407363584, 0.3580802054560963, 0.371327571832954, 0.31161591526876725, 0.3480678549663505, 0.32451843796063906, 0.3473169808112197]
2022-01-23 19:48:27:INFO:-------------Training local models-------------
2022-01-23 19:50:33:INFO:-------------Aggregating local models-------------
2022-01-23 19:50:34:INFO:-------------Round number: 20-------------
2022-01-23 19:50:34:INFO:-------------Sending models-------------
2022-01-23 19:50:34:INFO:-------------Evaluating models-------------
2022-01-23 19:50:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:50:34:INFO:Accuracy = [0.8760804020100502, 0.8824120603015075, 0.8985929648241207, 0.8894472361809045, 0.8980904522613066, 0.8907537688442211, 0.9034170854271357, 0.9005025125628141, 0.8995979899497487, 0.8893467336683417]
2022-01-23 19:50:34:INFO:Loss = [0.3657758906858051, 0.34668470387482764, 0.3738727654943514, 0.38896210978378604, 0.3589274586744644, 0.3716292297420789, 0.3108210127757413, 0.34642100274263316, 0.3232680773315717, 0.3470281795341166]
2022-01-23 19:50:34:INFO:-------------Training local models-------------
2022-01-23 19:52:41:INFO:-------------Aggregating local models-------------
2022-01-23 19:52:42:INFO:-------------Round number: 21-------------
2022-01-23 19:52:42:INFO:-------------Sending models-------------
2022-01-23 19:52:42:INFO:-------------Evaluating models-------------
2022-01-23 19:52:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:52:42:INFO:Accuracy = [0.8748743718592965, 0.8826130653266332, 0.8982914572864321, 0.8895477386934674, 0.8980904522613066, 0.8901507537688442, 0.9041206030150754, 0.9006030150753769, 0.9002010050251257, 0.8890452261306533]
2022-01-23 19:52:42:INFO:Loss = [0.36730422431500115, 0.3457257151603699, 0.37367078931487385, 0.38874372345718305, 0.36004875652754126, 0.3719360196410711, 0.31050765776805506, 0.3448496058059098, 0.32224972298995935, 0.34702927518130544]
2022-01-23 19:52:42:INFO:-------------Training local models-------------
2022-01-23 19:54:49:INFO:-------------Aggregating local models-------------
2022-01-23 19:54:50:INFO:-------------Round number: 22-------------
2022-01-23 19:54:50:INFO:-------------Sending models-------------
2022-01-23 19:54:50:INFO:-------------Evaluating models-------------
2022-01-23 19:54:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:54:50:INFO:Accuracy = [0.8751758793969849, 0.8820100502512562, 0.8980904522613066, 0.8892462311557789, 0.8980904522613066, 0.8891457286432161, 0.9040201005025126, 0.9010050251256282, 0.9005025125628141, 0.8883417085427135]
2022-01-23 19:54:50:INFO:Loss = [0.36865910108964045, 0.34506737002775295, 0.3734783278637795, 0.3885665043215057, 0.36121468253471145, 0.3722775096270307, 0.31093933646176386, 0.34340067439941907, 0.32134119574748093, 0.3473703892686259]
2022-01-23 19:54:50:INFO:-------------Training local models-------------
2022-01-23 19:56:57:INFO:-------------Aggregating local models-------------
2022-01-23 19:56:58:INFO:-------------Round number: 23-------------
2022-01-23 19:56:58:INFO:-------------Sending models-------------
2022-01-23 19:56:58:INFO:-------------Evaluating models-------------
2022-01-23 19:56:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:56:58:INFO:Accuracy = [0.8744723618090452, 0.8820100502512562, 0.8976884422110553, 0.8890452261306533, 0.8978894472361809, 0.8888442211055276, 0.904321608040201, 0.9014070351758794, 0.9006030150753769, 0.8874371859296483]
2022-01-23 19:56:58:INFO:Loss = [0.3699271512690501, 0.34477303105982104, 0.37329856594603267, 0.38844858581696323, 0.3624863874672645, 0.37267051989109673, 0.3122764380266141, 0.3422085213002248, 0.3206983623492658, 0.34802741351439126]
2022-01-23 19:56:58:INFO:-------------Training local models-------------
2022-01-23 19:59:04:INFO:-------------Aggregating local models-------------
2022-01-23 19:59:05:INFO:-------------Round number: 24-------------
2022-01-23 19:59:05:INFO:-------------Sending models-------------
2022-01-23 19:59:05:INFO:-------------Evaluating models-------------
2022-01-23 19:59:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:59:06:INFO:Accuracy = [0.874070351758794, 0.8812060301507537, 0.8971859296482412, 0.8884422110552764, 0.8977889447236181, 0.8884422110552764, 0.904321608040201, 0.9010050251256282, 0.9004020100502512, 0.8865326633165829]
2022-01-23 19:59:06:INFO:Loss = [0.37092505522708796, 0.3447891234153479, 0.3730859130471196, 0.38837514959987085, 0.36373555016278025, 0.37313315047690615, 0.31440843873184604, 0.3412196395085685, 0.32009530846198003, 0.3490488309057514]
2022-01-23 19:59:06:INFO:-------------Training local models-------------
2022-01-23 20:01:12:INFO:-------------Aggregating local models-------------
2022-01-23 20:01:13:INFO:-------------Round number: 25-------------
2022-01-23 20:01:13:INFO:-------------Sending models-------------
2022-01-23 20:01:13:INFO:-------------Evaluating models-------------
2022-01-23 20:01:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:01:13:INFO:Accuracy = [0.8735678391959799, 0.8806030150753769, 0.8959798994974875, 0.8877386934673367, 0.8980904522613066, 0.8880402010050251, 0.9045226130653267, 0.9008040201005025, 0.9004020100502512, 0.8848241206030151]
2022-01-23 20:01:13:INFO:Loss = [0.37182876302968315, 0.3450901712005462, 0.37281515745062327, 0.38835503917243613, 0.3648621856267728, 0.37359420842860813, 0.3168348942967553, 0.340453849066442, 0.31975007566375346, 0.3504062843083137]
2022-01-23 20:01:13:INFO:-------------Training local models-------------
2022-01-23 20:03:20:INFO:-------------Aggregating local models-------------
2022-01-23 20:03:21:INFO:-------------Round number: 26-------------
2022-01-23 20:03:21:INFO:-------------Sending models-------------
2022-01-23 20:03:21:INFO:-------------Evaluating models-------------
2022-01-23 20:03:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:03:21:INFO:Accuracy = [0.8734673366834171, 0.8797989949748743, 0.895678391959799, 0.887537688442211, 0.8977889447236181, 0.8879396984924623, 0.904321608040201, 0.9006030150753769, 0.9003015075376885, 0.8834170854271357]
2022-01-23 20:03:21:INFO:Loss = [0.37244869311850276, 0.34568920417047627, 0.3725268093485329, 0.38838045725870374, 0.3659608795415217, 0.3740101971817975, 0.31946811204057785, 0.3399662871157105, 0.31956097109233916, 0.3518635428431046]
2022-01-23 20:03:21:INFO:-------------Training local models-------------
2022-01-23 20:05:28:INFO:-------------Aggregating local models-------------
2022-01-23 20:05:29:INFO:-------------Round number: 27-------------
2022-01-23 20:05:29:INFO:-------------Sending models-------------
2022-01-23 20:05:29:INFO:-------------Evaluating models-------------
2022-01-23 20:05:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:05:29:INFO:Accuracy = [0.8733668341708543, 0.8791959798994975, 0.8943718592964824, 0.8872361809045226, 0.8976884422110553, 0.8877386934673367, 0.9045226130653267, 0.9007035175879397, 0.9, 0.8831155778894473]
2022-01-23 20:05:29:INFO:Loss = [0.3731184616759794, 0.3465487939029483, 0.3722267724461292, 0.38839972648189297, 0.36702009226808596, 0.374422287222129, 0.3221797428249461, 0.33961249865479204, 0.3194752368495692, 0.35349984848918625]
2022-01-23 20:05:29:INFO:-------------Training local models-------------
2022-01-23 20:07:36:INFO:-------------Aggregating local models-------------
2022-01-23 20:07:37:INFO:-------------Round number: 28-------------
2022-01-23 20:07:37:INFO:-------------Sending models-------------
2022-01-23 20:07:37:INFO:-------------Evaluating models-------------
2022-01-23 20:07:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:07:37:INFO:Accuracy = [0.8731658291457286, 0.8785929648241206, 0.893467336683417, 0.887035175879397, 0.8976884422110553, 0.8871356783919598, 0.9046231155778894, 0.901105527638191, 0.8997989949748744, 0.8823115577889448]
2022-01-23 20:07:37:INFO:Loss = [0.3737685123280664, 0.34755041686134724, 0.3719053478097197, 0.38847322559835923, 0.3680727402469022, 0.37479946496498645, 0.3248715502269632, 0.3394521350537113, 0.3195822824485338, 0.35518248536478936]
2022-01-23 20:07:37:INFO:-------------Training local models-------------
2022-01-23 20:09:44:INFO:-------------Aggregating local models-------------
2022-01-23 20:09:45:INFO:-------------Round number: 29-------------
2022-01-23 20:09:45:INFO:-------------Sending models-------------
2022-01-23 20:09:45:INFO:-------------Evaluating models-------------
2022-01-23 20:09:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:09:45:INFO:Accuracy = [0.8734673366834171, 0.8784924623115578, 0.8925628140703518, 0.8866331658291458, 0.8975879396984925, 0.8865326633165829, 0.9047236180904522, 0.9008040201005025, 0.8995979899497487, 0.8821105527638191]
2022-01-23 20:09:45:INFO:Loss = [0.37436154290060303, 0.3487102470206256, 0.37159278150179875, 0.38855823724713157, 0.3690613858663856, 0.375219793475453, 0.32756893052988634, 0.3394777368960069, 0.3198812602452896, 0.35706573844555034]
2022-01-23 20:09:45:INFO:-------------Training local models-------------
2022-01-23 20:11:52:INFO:-------------Aggregating local models-------------
2022-01-23 20:11:53:INFO:-------------Round number: 30-------------
2022-01-23 20:11:53:INFO:-------------Sending models-------------
2022-01-23 20:11:53:INFO:-------------Evaluating models-------------
2022-01-23 20:11:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:11:53:INFO:Accuracy = [0.8725628140703517, 0.8777889447236181, 0.8919597989949749, 0.8863316582914573, 0.8975879396984925, 0.8861306532663317, 0.9046231155778894, 0.9007035175879397, 0.8992964824120603, 0.8824120603015075]
2022-01-23 20:11:53:INFO:Loss = [0.3750421902043137, 0.35003426671028137, 0.37127567730357297, 0.3886597707642982, 0.37006773271752363, 0.37564619357262424, 0.3302760936200488, 0.339660219511195, 0.32027057532090036, 0.3589724248378121]
2022-01-23 20:11:53:INFO:-------------Training local models-------------
2022-01-23 20:14:00:INFO:-------------Aggregating local models-------------
2022-01-23 20:14:01:INFO:-------------Round number: 31-------------
2022-01-23 20:14:01:INFO:-------------Sending models-------------
2022-01-23 20:14:01:INFO:-------------Evaluating models-------------
2022-01-23 20:14:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:14:01:INFO:Accuracy = [0.8722613065326633, 0.8769849246231156, 0.8911557788944724, 0.8866331658291458, 0.8975879396984925, 0.8858291457286432, 0.9045226130653267, 0.9007035175879397, 0.8988944723618091, 0.8821105527638191]
2022-01-23 20:14:01:INFO:Loss = [0.3759065171582016, 0.3514726978151043, 0.37096347101968735, 0.38880906991623154, 0.3711372098731036, 0.37615044602197617, 0.3331053069121106, 0.3399476284657291, 0.3207385544501357, 0.36094979919380876]
2022-01-23 20:14:01:INFO:-------------Training local models-------------
2022-01-23 20:16:07:INFO:-------------Aggregating local models-------------
2022-01-23 20:16:08:INFO:-------------Round number: 32-------------
2022-01-23 20:16:08:INFO:-------------Sending models-------------
2022-01-23 20:16:09:INFO:-------------Evaluating models-------------
2022-01-23 20:16:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:16:09:INFO:Accuracy = [0.8714572864321608, 0.8764824120603015, 0.8906532663316583, 0.8866331658291458, 0.8974874371859296, 0.885929648241206, 0.9045226130653267, 0.9006030150753769, 0.8987939698492462, 0.8814070351758794]
2022-01-23 20:16:09:INFO:Loss = [0.37682935490680103, 0.35308528051304455, 0.3707101150373718, 0.3889685960570772, 0.37218855149182845, 0.3767400355494801, 0.33597442764208546, 0.3404246017561486, 0.3213058585797123, 0.36309535179904956]
2022-01-23 20:16:09:INFO:-------------Training local models-------------
2022-01-23 20:18:15:INFO:-------------Aggregating local models-------------
2022-01-23 20:18:16:INFO:-------------Round number: 33-------------
2022-01-23 20:18:16:INFO:-------------Sending models-------------
2022-01-23 20:18:16:INFO:-------------Evaluating models-------------
2022-01-23 20:18:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:18:17:INFO:Accuracy = [0.8716582914572865, 0.8763819095477386, 0.8903517587939699, 0.8863316582914573, 0.8974874371859296, 0.885929648241206, 0.9046231155778894, 0.9006030150753769, 0.8989949748743719, 0.8817085427135678]
2022-01-23 20:18:17:INFO:Loss = [0.377775342320677, 0.35468532721600937, 0.3705091731033133, 0.3891866082821659, 0.37326988832435415, 0.3773857410529151, 0.3387722245893727, 0.34101962893452475, 0.3220462824531536, 0.36518452709643684]
2022-01-23 20:18:17:INFO:-------------Training local models-------------
2022-01-23 20:20:23:INFO:-------------Aggregating local models-------------
2022-01-23 20:20:24:INFO:-------------Round number: 34-------------
2022-01-23 20:20:24:INFO:-------------Sending models-------------
2022-01-23 20:20:24:INFO:-------------Evaluating models-------------
2022-01-23 20:20:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:20:25:INFO:Accuracy = [0.8717587939698492, 0.8750753768844222, 0.8898492462311558, 0.8867336683417085, 0.8975879396984925, 0.8850251256281407, 0.9046231155778894, 0.9008040201005025, 0.8985929648241207, 0.8814070351758794]
2022-01-23 20:20:25:INFO:Loss = [0.3787095425416477, 0.35635155469328916, 0.37036632038840095, 0.3895240423068329, 0.374374972216448, 0.378078328155393, 0.3416248166725395, 0.34174878483441606, 0.32286405039193045, 0.3674865359037965]
2022-01-23 20:20:25:INFO:-------------Training local models-------------
2022-01-23 20:22:31:INFO:-------------Aggregating local models-------------
2022-01-23 20:22:32:INFO:-------------Round number: 35-------------
2022-01-23 20:22:32:INFO:-------------Sending models-------------
2022-01-23 20:22:32:INFO:-------------Evaluating models-------------
2022-01-23 20:22:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:22:32:INFO:Accuracy = [0.871356783919598, 0.8750753768844222, 0.8882412060301508, 0.8865326633165829, 0.8974874371859296, 0.8848241206030151, 0.9047236180904522, 0.9014070351758794, 0.8985929648241207, 0.8808040201005025]
2022-01-23 20:22:32:INFO:Loss = [0.3797045691528512, 0.35812345686270364, 0.3702500510455376, 0.3899527993333999, 0.37558202917252353, 0.37888550623577444, 0.34450227596116106, 0.34260843941314734, 0.32387282545842117, 0.3699062375267546]
2022-01-23 20:22:32:INFO:-------------Training local models-------------
2022-01-23 20:24:39:INFO:-------------Aggregating local models-------------
2022-01-23 20:24:40:INFO:-------------Round number: 36-------------
2022-01-23 20:24:40:INFO:-------------Sending models-------------
2022-01-23 20:24:40:INFO:-------------Evaluating models-------------
2022-01-23 20:24:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:24:40:INFO:Accuracy = [0.8712562814070351, 0.8752763819095477, 0.8877386934673367, 0.8861306532663317, 0.8973869346733668, 0.8846231155778894, 0.9047236180904522, 0.9013065326633166, 0.898391959798995, 0.8805025125628141]
2022-01-23 20:24:40:INFO:Loss = [0.38085155361261797, 0.36002171683551076, 0.3702166576181824, 0.390463675536103, 0.37681768976863306, 0.3798062191836199, 0.347479984157218, 0.34356480582275584, 0.32491134009768613, 0.3723111745700165]
2022-01-23 20:24:40:INFO:-------------Training local models-------------
2022-01-23 20:26:46:INFO:-------------Aggregating local models-------------
2022-01-23 20:26:47:INFO:-------------Round number: 37-------------
2022-01-23 20:26:47:INFO:-------------Sending models-------------
2022-01-23 20:26:48:INFO:-------------Evaluating models-------------
2022-01-23 20:26:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:26:48:INFO:Accuracy = [0.8712562814070351, 0.8757788944723618, 0.8876381909547739, 0.8864321608040201, 0.8974874371859296, 0.8840201005025126, 0.9048241206030151, 0.9017085427135678, 0.8986934673366834, 0.8802010050251257]
2022-01-23 20:26:48:INFO:Loss = [0.3820155873969572, 0.3620162258795158, 0.37027739445168767, 0.39101754016612644, 0.3781102931679194, 0.38076869327219287, 0.3504186639159768, 0.34461805493987385, 0.326031192463247, 0.37467323805219566]
2022-01-23 20:26:48:INFO:-------------Training local models-------------
2022-01-23 20:28:54:INFO:-------------Aggregating local models-------------
2022-01-23 20:28:55:INFO:-------------Round number: 38-------------
2022-01-23 20:28:55:INFO:-------------Sending models-------------
2022-01-23 20:28:55:INFO:-------------Evaluating models-------------
2022-01-23 20:28:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:28:56:INFO:Accuracy = [0.870854271356784, 0.8755778894472361, 0.8866331658291458, 0.8865326633165829, 0.8972864321608041, 0.8839195979899498, 0.9048241206030151, 0.9015075376884422, 0.8994974874371859, 0.8802010050251257]
2022-01-23 20:28:56:INFO:Loss = [0.3829875673780489, 0.36405140206442405, 0.370420612132729, 0.39168124582300234, 0.3794525984543652, 0.3818451820605963, 0.35339465651757096, 0.3457772252547681, 0.32711022837677195, 0.3771714565142914]
2022-01-23 20:28:56:INFO:-------------Training local models-------------
2022-01-23 20:31:02:INFO:-------------Aggregating local models-------------
2022-01-23 20:31:03:INFO:-------------Round number: 39-------------
2022-01-23 20:31:03:INFO:-------------Sending models-------------
2022-01-23 20:31:03:INFO:-------------Evaluating models-------------
2022-01-23 20:31:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:31:03:INFO:Accuracy = [0.8695477386934674, 0.8754773869346734, 0.8863316582914573, 0.8866331658291458, 0.8970854271356784, 0.8833165829145728, 0.9048241206030151, 0.901608040201005, 0.8993969849246232, 0.88]
2022-01-23 20:31:03:INFO:Loss = [0.38429562500373804, 0.3661904580629052, 0.370634346601352, 0.39239903535675164, 0.3809322283495611, 0.3830621020877781, 0.3564478148654777, 0.3470438360868387, 0.32837174181363094, 0.37976483064680244]
2022-01-23 20:31:03:INFO:-------------Training local models-------------
2022-01-23 20:33:10:INFO:-------------Aggregating local models-------------
2022-01-23 20:33:11:INFO:-------------Round number: 40-------------
2022-01-23 20:33:11:INFO:-------------Sending models-------------
2022-01-23 20:33:11:INFO:-------------Evaluating models-------------
2022-01-23 20:33:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:33:11:INFO:Accuracy = [0.8698492462311558, 0.8748743718592965, 0.8861306532663317, 0.8862311557788944, 0.8969849246231156, 0.8829145728643216, 0.9048241206030151, 0.9014070351758794, 0.8992964824120603, 0.8792964824120603]
2022-01-23 20:33:11:INFO:Loss = [0.38558582010580666, 0.3683742590286025, 0.3709491948087012, 0.39318245469625274, 0.38240088979203496, 0.384348021979308, 0.35958972165358705, 0.34841178604705847, 0.3295769877170199, 0.3824304083184381]
2022-01-23 20:33:11:INFO:-------------Training local models-------------
2022-01-23 20:35:17:INFO:-------------Aggregating local models-------------
2022-01-23 20:35:18:INFO:-------------Round number: 41-------------
2022-01-23 20:35:18:INFO:-------------Sending models-------------
2022-01-23 20:35:18:INFO:-------------Evaluating models-------------
2022-01-23 20:35:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:35:19:INFO:Accuracy = [0.8694472361809045, 0.8741708542713568, 0.8854271356783919, 0.8861306532663317, 0.89678391959799, 0.8822110552763819, 0.9048241206030151, 0.901105527638191, 0.8991959798994975, 0.8790954773869347]
2022-01-23 20:35:19:INFO:Loss = [0.3869375119257213, 0.3706641188218965, 0.37136561502164334, 0.39407901188836025, 0.3840111266428502, 0.38569208470421223, 0.3627901515033068, 0.3498869109992406, 0.3307935668894993, 0.3850556948975702]
2022-01-23 20:35:19:INFO:-------------Training local models-------------
2022-01-23 20:37:25:INFO:-------------Aggregating local models-------------
2022-01-23 20:37:26:INFO:-------------Round number: 42-------------
2022-01-23 20:37:26:INFO:-------------Sending models-------------
2022-01-23 20:37:26:INFO:-------------Evaluating models-------------
2022-01-23 20:37:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:37:26:INFO:Accuracy = [0.8693467336683417, 0.8744723618090452, 0.8847236180904523, 0.8860301507537689, 0.8966834170854271, 0.8818090452261307, 0.9049246231155779, 0.9008040201005025, 0.8990954773869346, 0.8786934673366834]
2022-01-23 20:37:26:INFO:Loss = [0.3882812132787465, 0.37305960074141997, 0.3718757557509533, 0.39504033147390166, 0.38560900586334307, 0.38718207861909915, 0.3660467997615708, 0.35143778042577617, 0.33203726617535156, 0.3877091728263165]
2022-01-23 20:37:26:INFO:-------------Training local models-------------
2022-01-23 20:39:32:INFO:-------------Aggregating local models-------------
2022-01-23 20:39:33:INFO:-------------Round number: 43-------------
2022-01-23 20:39:33:INFO:-------------Sending models-------------
2022-01-23 20:39:33:INFO:-------------Evaluating models-------------
2022-01-23 20:39:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:39:33:INFO:Accuracy = [0.869145728643216, 0.8742713567839197, 0.8839195979899498, 0.8864321608040201, 0.8963819095477387, 0.881608040201005, 0.9048241206030151, 0.9002010050251257, 0.8986934673366834, 0.8785929648241206]
2022-01-23 20:39:33:INFO:Loss = [0.38974047141458523, 0.3755067124139124, 0.3724874066348052, 0.3961053975862474, 0.38723175070393623, 0.38875640741544754, 0.3692976577247226, 0.35308290980569085, 0.3333689637819127, 0.3903994555748887]
2022-01-23 20:39:33:INFO:-------------Training local models-------------
2022-01-23 20:41:38:INFO:-------------Aggregating local models-------------
2022-01-23 20:41:39:INFO:-------------Round number: 44-------------
2022-01-23 20:41:39:INFO:-------------Sending models-------------
2022-01-23 20:41:39:INFO:-------------Evaluating models-------------
2022-01-23 20:41:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:41:39:INFO:Accuracy = [0.8692462311557789, 0.8738693467336683, 0.8836180904522613, 0.8863316582914573, 0.8962814070351759, 0.8811055276381909, 0.9048241206030151, 0.9, 0.8981909547738693, 0.8780904522613066]
2022-01-23 20:41:39:INFO:Loss = [0.391281472827921, 0.37806857695531604, 0.37320383874016194, 0.3972964166995868, 0.3889956788801069, 0.3904764083162624, 0.37260101671241713, 0.35481953635886687, 0.3348097543620584, 0.3931926183365098]
2022-01-23 20:41:39:INFO:-------------Training local models-------------
2022-01-23 20:43:45:INFO:-------------Aggregating local models-------------
2022-01-23 20:43:46:INFO:-------------Round number: 45-------------
2022-01-23 20:43:46:INFO:-------------Sending models-------------
2022-01-23 20:43:46:INFO:-------------Evaluating models-------------
2022-01-23 20:43:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:43:46:INFO:Accuracy = [0.8692462311557789, 0.8727638190954774, 0.88321608040201, 0.8861306532663317, 0.8962814070351759, 0.8809045226130653, 0.9047236180904522, 0.8997989949748744, 0.8979899497487437, 0.8781909547738693]
2022-01-23 20:43:46:INFO:Loss = [0.3926678955854483, 0.38064514512392744, 0.374047822988213, 0.39857840972330105, 0.3907500619265302, 0.3923266849026608, 0.3758723085749679, 0.35660678492718606, 0.33630509068019426, 0.3960274273726209]
2022-01-23 20:43:46:INFO:-------------Training local models-------------
2022-01-23 20:45:51:INFO:-------------Aggregating local models-------------
2022-01-23 20:45:52:INFO:-------------Round number: 46-------------
2022-01-23 20:45:52:INFO:-------------Sending models-------------
2022-01-23 20:45:52:INFO:-------------Evaluating models-------------
2022-01-23 20:45:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:45:52:INFO:Accuracy = [0.8693467336683417, 0.8725628140703517, 0.8831155778894473, 0.8861306532663317, 0.8962814070351759, 0.8802010050251257, 0.9046231155778894, 0.8994974874371859, 0.8981909547738693, 0.8781909547738693]
2022-01-23 20:45:52:INFO:Loss = [0.3941550368639692, 0.38330486252080254, 0.3750004000100658, 0.399970398326615, 0.39251680559848423, 0.39423068788782434, 0.37906429499689603, 0.35843104004260884, 0.3378322220327866, 0.3988284622904044]
2022-01-23 20:45:52:INFO:-------------Training local models-------------
2022-01-23 20:47:57:INFO:-------------Aggregating local models-------------
2022-01-23 20:47:58:INFO:-------------Round number: 47-------------
2022-01-23 20:47:58:INFO:-------------Sending models-------------
2022-01-23 20:47:58:INFO:-------------Evaluating models-------------
2022-01-23 20:47:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:47:59:INFO:Accuracy = [0.869145728643216, 0.8722613065326633, 0.8830150753768844, 0.8854271356783919, 0.8961809045226131, 0.88, 0.9046231155778894, 0.8992964824120603, 0.8980904522613066, 0.8777889447236181]
2022-01-23 20:47:59:INFO:Loss = [0.39574597843328313, 0.38592198895449614, 0.37605136902488057, 0.40154215349024863, 0.3943256864595653, 0.3962701556071564, 0.3823920984474015, 0.36032814191813445, 0.339399950288648, 0.40169216370462774]
2022-01-23 20:47:59:INFO:-------------Training local models-------------
2022-01-23 20:50:04:INFO:-------------Aggregating local models-------------
2022-01-23 20:50:05:INFO:-------------Round number: 48-------------
2022-01-23 20:50:05:INFO:-------------Sending models-------------
2022-01-23 20:50:05:INFO:-------------Evaluating models-------------
2022-01-23 20:50:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:50:05:INFO:Accuracy = [0.8694472361809045, 0.8717587939698492, 0.8834170854271357, 0.8849246231155778, 0.8960804020100502, 0.8792964824120603, 0.9046231155778894, 0.8990954773869346, 0.8984924623115578, 0.8776884422110552]
2022-01-23 20:50:05:INFO:Loss = [0.39743465604494566, 0.3886086286312372, 0.3771985932510702, 0.40314690611470283, 0.396229959013474, 0.39840681394140925, 0.3856847406758098, 0.3622679069413612, 0.34105022333974216, 0.4045668430064791]
2022-01-23 20:50:05:INFO:-------------Training local models-------------
2022-01-23 20:52:10:INFO:-------------Aggregating local models-------------
2022-01-23 20:52:11:INFO:-------------Round number: 49-------------
2022-01-23 20:52:11:INFO:-------------Sending models-------------
2022-01-23 20:52:11:INFO:-------------Evaluating models-------------
2022-01-23 20:52:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:52:11:INFO:Accuracy = [0.8692462311557789, 0.8712562814070351, 0.8828140703517587, 0.8847236180904523, 0.8961809045226131, 0.8786934673366834, 0.9046231155778894, 0.8991959798994975, 0.8984924623115578, 0.877286432160804]
2022-01-23 20:52:11:INFO:Loss = [0.3992422669377159, 0.39134154547399014, 0.37849873723696226, 0.40489252742810466, 0.398181978182577, 0.40066078095579866, 0.3891462878898563, 0.3642792325822552, 0.34272812898434585, 0.40745929812067117]
2022-01-23 20:52:11:INFO:-------------Training local models-------------
2022-01-23 20:54:17:INFO:-------------Aggregating local models-------------
2022-01-23 20:54:18:INFO:-------------Round number: 50-------------
2022-01-23 20:54:18:INFO:-------------Sending models-------------
2022-01-23 20:54:18:INFO:-------------Evaluating models-------------
2022-01-23 20:54:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:54:18:INFO:Accuracy = [0.8689447236180905, 0.8709547738693467, 0.8818090452261307, 0.884321608040201, 0.8960804020100502, 0.8777889447236181, 0.9047236180904522, 0.8990954773869346, 0.8982914572864321, 0.8770854271356784]
2022-01-23 20:54:18:INFO:Loss = [0.4009688596929138, 0.3940944023168267, 0.37990837675243166, 0.40667416657035677, 0.40017584071087475, 0.4030402555837104, 0.39256223623088593, 0.3663819996855367, 0.344460890820278, 0.4104613507512826]
2022-01-23 20:54:18:INFO:-------------Training local models-------------
2022-01-23 20:56:23:INFO:-------------Aggregating local models-------------
2022-01-23 20:56:24:INFO:-------------Round number: 51-------------
2022-01-23 20:56:24:INFO:-------------Sending models-------------
2022-01-23 20:56:24:INFO:-------------Evaluating models-------------
2022-01-23 20:56:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:56:24:INFO:Accuracy = [0.8689447236180905, 0.8714572864321608, 0.8817085427135678, 0.8841206030150753, 0.895678391959799, 0.8775879396984925, 0.9047236180904522, 0.8991959798994975, 0.8979899497487437, 0.8769849246231156]
2022-01-23 20:56:24:INFO:Loss = [0.402712205846106, 0.39690566137807454, 0.38140369614764075, 0.40857615602675396, 0.40218636797900176, 0.4054714069893612, 0.39606457202924633, 0.36856147572023784, 0.34622420827348027, 0.4134717935593284]
2022-01-23 20:56:24:INFO:-------------Training local models-------------
2022-01-23 20:58:29:INFO:-------------Aggregating local models-------------
2022-01-23 20:58:30:INFO:-------------Round number: 52-------------
2022-01-23 20:58:30:INFO:-------------Sending models-------------
2022-01-23 20:58:31:INFO:-------------Evaluating models-------------
2022-01-23 20:58:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:58:31:INFO:Accuracy = [0.8690452261306533, 0.8717587939698492, 0.8809045226130653, 0.8842211055276382, 0.8957788944723618, 0.8777889447236181, 0.9047236180904522, 0.8993969849246232, 0.8979899497487437, 0.8775879396984925]
2022-01-23 20:58:31:INFO:Loss = [0.4044239092711827, 0.3997996756479369, 0.3830180651877993, 0.4105632384518283, 0.4042642008719133, 0.4079908321251222, 0.39958949922935, 0.370758447665066, 0.3480069719666812, 0.4164193416360635]
2022-01-23 20:58:31:INFO:-------------Training local models-------------
2022-01-23 21:00:36:INFO:-------------Aggregating local models-------------
2022-01-23 21:00:37:INFO:-------------Round number: 53-------------
2022-01-23 21:00:37:INFO:-------------Sending models-------------
2022-01-23 21:00:37:INFO:-------------Evaluating models-------------
2022-01-23 21:00:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:00:37:INFO:Accuracy = [0.8688442211055276, 0.8714572864321608, 0.8804020100502512, 0.8841206030150753, 0.8957788944723618, 0.8777889447236181, 0.9047236180904522, 0.8991959798994975, 0.8978894472361809, 0.8773869346733668]
2022-01-23 21:00:37:INFO:Loss = [0.40637323934229175, 0.40271806806775196, 0.3847594738905154, 0.41264835614055845, 0.4063996127502403, 0.4106079086885979, 0.40312505999448983, 0.37295470704984424, 0.34975725112847944, 0.419308925843119]
2022-01-23 21:00:37:INFO:-------------Training local models-------------
2022-01-23 21:02:42:INFO:-------------Aggregating local models-------------
2022-01-23 21:02:43:INFO:-------------Round number: 54-------------
2022-01-23 21:02:43:INFO:-------------Sending models-------------
2022-01-23 21:02:43:INFO:-------------Evaluating models-------------
2022-01-23 21:02:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:02:43:INFO:Accuracy = [0.8684422110552764, 0.8711557788944724, 0.8793969849246231, 0.8835175879396985, 0.8952763819095477, 0.8774874371859297, 0.9047236180904522, 0.8989949748743719, 0.8976884422110553, 0.8774874371859297]
2022-01-23 21:02:43:INFO:Loss = [0.40830860245766953, 0.4056655846948001, 0.38657187756581524, 0.41481607074114546, 0.408494599800014, 0.41324894721783584, 0.40661606948557144, 0.37520274385135977, 0.35151532067725405, 0.4222451731487734]
2022-01-23 21:02:43:INFO:-------------Training local models-------------
2022-01-23 21:04:49:INFO:-------------Aggregating local models-------------
2022-01-23 21:04:50:INFO:-------------Round number: 55-------------
2022-01-23 21:04:50:INFO:-------------Sending models-------------
2022-01-23 21:04:50:INFO:-------------Evaluating models-------------
2022-01-23 21:04:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:04:50:INFO:Accuracy = [0.8678391959798994, 0.8709547738693467, 0.8791959798994975, 0.8830150753768844, 0.8949748743718593, 0.8770854271356784, 0.9047236180904522, 0.8988944723618091, 0.8973869346733668, 0.8773869346733668]
2022-01-23 21:04:50:INFO:Loss = [0.41026829759679245, 0.4086365764165044, 0.388498126112636, 0.4170415859725607, 0.4106082275285194, 0.41597385292676226, 0.4100764692429308, 0.377540418999878, 0.35332527037840994, 0.4253339911226052]
2022-01-23 21:04:50:INFO:-------------Training local models-------------
2022-01-23 21:06:55:INFO:-------------Aggregating local models-------------
2022-01-23 21:06:56:INFO:-------------Round number: 56-------------
2022-01-23 21:06:56:INFO:-------------Sending models-------------
2022-01-23 21:06:56:INFO:-------------Evaluating models-------------
2022-01-23 21:06:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:06:56:INFO:Accuracy = [0.8680402010050251, 0.870854271356784, 0.8788944723618091, 0.8826130653266332, 0.8944723618090452, 0.8771859296482412, 0.9045226130653267, 0.8986934673366834, 0.8970854271356784, 0.8773869346733668]
2022-01-23 21:06:56:INFO:Loss = [0.4121657952890923, 0.41158459743662695, 0.3904880806429302, 0.4192936525272964, 0.4127556331193627, 0.41877396292422886, 0.4135065655614221, 0.3798810063894071, 0.3551413623531859, 0.4283987217812083]
2022-01-23 21:06:56:INFO:-------------Training local models-------------
2022-01-23 21:09:01:INFO:-------------Aggregating local models-------------
2022-01-23 21:09:02:INFO:-------------Round number: 57-------------
2022-01-23 21:09:02:INFO:-------------Sending models-------------
2022-01-23 21:09:02:INFO:-------------Evaluating models-------------
2022-01-23 21:09:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:09:03:INFO:Accuracy = [0.8682412060301508, 0.8707537688442211, 0.878391959798995, 0.8825125628140703, 0.8942713567839196, 0.8770854271356784, 0.9044221105527638, 0.8986934673366834, 0.8966834170854271, 0.877286432160804]
2022-01-23 21:09:03:INFO:Loss = [0.41400820451166165, 0.4145181673255997, 0.39255256868487026, 0.42156854691217893, 0.4148710693546276, 0.42159059449056885, 0.41691262394350126, 0.38222810026988313, 0.3569387198992111, 0.4314218542384143]
2022-01-23 21:09:03:INFO:-------------Training local models-------------
2022-01-23 21:11:08:INFO:-------------Aggregating local models-------------
2022-01-23 21:11:09:INFO:-------------Round number: 58-------------
2022-01-23 21:11:09:INFO:-------------Sending models-------------
2022-01-23 21:11:09:INFO:-------------Evaluating models-------------
2022-01-23 21:11:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:11:09:INFO:Accuracy = [0.8679396984924623, 0.8705527638190955, 0.8774874371859297, 0.8818090452261307, 0.8938693467336684, 0.8765829145728643, 0.904321608040201, 0.8989949748743719, 0.8966834170854271, 0.8773869346733668]
2022-01-23 21:11:09:INFO:Loss = [0.4159397141418265, 0.4174797672722208, 0.3946755441588972, 0.423920528523287, 0.4170810604215267, 0.42449249394574956, 0.4203174748684949, 0.38466495979371385, 0.3587377871101226, 0.4345161781538671]
2022-01-23 21:11:09:INFO:-------------Training local models-------------
2022-01-23 21:13:14:INFO:-------------Aggregating local models-------------
2022-01-23 21:13:15:INFO:-------------Round number: 59-------------
2022-01-23 21:13:15:INFO:-------------Sending models-------------
2022-01-23 21:13:15:INFO:-------------Evaluating models-------------
2022-01-23 21:13:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:13:15:INFO:Accuracy = [0.8683417085427135, 0.8706532663316583, 0.8768844221105527, 0.8814070351758794, 0.893467336683417, 0.8759798994974874, 0.9044221105527638, 0.8986934673366834, 0.8961809045226131, 0.8773869346733668]
2022-01-23 21:13:15:INFO:Loss = [0.41797198512446343, 0.420461839167916, 0.396850124375904, 0.42635109286811484, 0.4193508190725317, 0.4274688506845254, 0.4237081266348203, 0.38707166191321524, 0.36063376458445984, 0.43758494081209653]
2022-01-23 21:13:15:INFO:-------------Training local models-------------
2022-01-23 21:15:21:INFO:-------------Aggregating local models-------------
