2022-01-23 19:05:52:INFO:-------------Round number: 0-------------
2022-01-23 19:05:52:INFO:-------------Sending models-------------
2022-01-23 19:05:52:INFO:-------------Evaluating models-------------
2022-01-23 19:05:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:05:52:INFO:Accuracy = [0.9, 0.9, 0.9, 0.1, 0.9, 0.1, 0.9, 0.1005, 0.9, 0.3025]
2022-01-23 19:05:52:INFO:Loss = [0.662953394651413, 0.6194361120462417, 0.6740155637264251, 0.7170065671205521, 0.6775219947099685, 0.7550831705331802, 0.6259431272745133, 0.7044017463922501, 0.6680530607700348, 0.6947273313999176]
2022-01-23 19:05:52:INFO:-------------Training local models-------------
2022-01-23 19:21:51:INFO:-------------Aggregating local models-------------
2022-01-23 19:21:53:INFO:-------------Round number: 1-------------
2022-01-23 19:21:53:INFO:-------------Sending models-------------
2022-01-23 19:21:53:INFO:-------------Evaluating models-------------
2022-01-23 19:21:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:21:53:INFO:Accuracy = [0.9, 0.9, 0.9, 0.9005, 0.8995, 0.9045, 0.906, 0.9005, 0.9, 0.9005]
2022-01-23 19:21:53:INFO:Loss = [0.17908295256784185, 0.17511774466838687, 0.20031232013134287, 0.2028027089429088, 0.20081122774863616, 0.19888798483880238, 0.18303277133964002, 0.1872523003956303, 0.1905295164673589, 0.1847074358840473]
2022-01-23 19:21:53:INFO:-------------Training local models-------------
2022-01-23 19:38:28:INFO:-------------Aggregating local models-------------
2022-01-23 19:38:30:INFO:-------------Round number: 2-------------
2022-01-23 19:38:30:INFO:-------------Sending models-------------
2022-01-23 19:38:30:INFO:-------------Evaluating models-------------
2022-01-23 19:38:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:38:30:INFO:Accuracy = [0.9, 0.9005, 0.9005, 0.9, 0.903, 0.9035, 0.9105, 0.908, 0.9015, 0.9025]
2022-01-23 19:38:30:INFO:Loss = [0.17688773372210562, 0.17791861302393955, 0.1964506892953068, 0.19816753404738846, 0.19775200077565386, 0.19652112397307064, 0.17056520364712924, 0.17623803360620513, 0.1899236981291324, 0.18042302397079765]
2022-01-23 19:38:30:INFO:-------------Training local models-------------
2022-01-23 19:54:54:INFO:-------------Aggregating local models-------------
2022-01-23 19:54:55:INFO:-------------Round number: 3-------------
2022-01-23 19:54:55:INFO:-------------Sending models-------------
2022-01-23 19:54:55:INFO:-------------Evaluating models-------------
2022-01-23 19:54:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 19:54:56:INFO:Accuracy = [0.9045, 0.906, 0.901, 0.9, 0.907, 0.904, 0.913, 0.9085, 0.905, 0.905]
2022-01-23 19:54:56:INFO:Loss = [0.20140288273396437, 0.2097055801510578, 0.19638834097422658, 0.19765259421546943, 0.19949364592321217, 0.19909773291874444, 0.1637766094325343, 0.17026592825131956, 0.19201608798466624, 0.18275161352066788]
2022-01-23 19:54:56:INFO:-------------Training local models-------------
2022-01-23 20:11:16:INFO:-------------Aggregating local models-------------
2022-01-23 20:11:17:INFO:-------------Round number: 4-------------
2022-01-23 20:11:17:INFO:-------------Sending models-------------
2022-01-23 20:11:18:INFO:-------------Evaluating models-------------
2022-01-23 20:11:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:11:18:INFO:Accuracy = [0.9055, 0.9045, 0.9005, 0.9015, 0.9095, 0.9095, 0.909, 0.906, 0.9065, 0.908]
2022-01-23 20:11:18:INFO:Loss = [0.2517708294064505, 0.2652446023930679, 0.1987606923794374, 0.199576900152897, 0.21025175437825966, 0.21108309022529284, 0.16692688666516914, 0.17388270790106616, 0.20223225583176827, 0.19425876204186351]
2022-01-23 20:11:18:INFO:-------------Training local models-------------
2022-01-23 20:27:38:INFO:-------------Aggregating local models-------------
2022-01-23 20:27:39:INFO:-------------Round number: 5-------------
2022-01-23 20:27:39:INFO:-------------Sending models-------------
2022-01-23 20:27:39:INFO:-------------Evaluating models-------------
2022-01-23 20:27:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:27:39:INFO:Accuracy = [0.904, 0.904, 0.9005, 0.902, 0.912, 0.9125, 0.908, 0.9055, 0.9095, 0.911]
2022-01-23 20:27:39:INFO:Loss = [0.3140123985664104, 0.32828055390127703, 0.20351952642377, 0.20403597144904778, 0.22923640370718204, 0.23123724893303005, 0.17672233619960026, 0.18347013760649133, 0.2325587176703266, 0.2253187089561834]
2022-01-23 20:27:39:INFO:-------------Training local models-------------
2022-01-23 20:44:00:INFO:-------------Aggregating local models-------------
2022-01-23 20:44:01:INFO:-------------Round number: 6-------------
2022-01-23 20:44:01:INFO:-------------Sending models-------------
2022-01-23 20:44:01:INFO:-------------Evaluating models-------------
2022-01-23 20:44:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 20:44:01:INFO:Accuracy = [0.9035, 0.902, 0.9005, 0.9015, 0.909, 0.911, 0.912, 0.9095, 0.9075, 0.908]
2022-01-23 20:44:01:INFO:Loss = [0.36842868969106346, 0.3811519909388153, 0.2125015703612007, 0.21268906860714196, 0.24499276104324963, 0.24745618567976635, 0.1933065932345926, 0.1996200326437247, 0.28056073532352455, 0.2724281987575523]
2022-01-23 20:44:01:INFO:-------------Training local models-------------
2022-01-23 21:00:21:INFO:-------------Aggregating local models-------------
2022-01-23 21:00:23:INFO:-------------Round number: 7-------------
2022-01-23 21:00:23:INFO:-------------Sending models-------------
2022-01-23 21:00:23:INFO:-------------Evaluating models-------------
2022-01-23 21:00:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:00:23:INFO:Accuracy = [0.9025, 0.9015, 0.902, 0.903, 0.9035, 0.9045, 0.9135, 0.9105, 0.907, 0.9075]
2022-01-23 21:00:23:INFO:Loss = [0.41271754315966974, 0.42394039807550143, 0.22668754244004957, 0.226332243354409, 0.25665597343104307, 0.25930603574452105, 0.21851790613582125, 0.22415775476474664, 0.3185143626513309, 0.3105618048924953]
2022-01-23 21:00:23:INFO:-------------Training local models-------------
2022-01-23 21:16:43:INFO:-------------Aggregating local models-------------
2022-01-23 21:16:44:INFO:-------------Round number: 8-------------
2022-01-23 21:16:44:INFO:-------------Sending models-------------
2022-01-23 21:16:45:INFO:-------------Evaluating models-------------
2022-01-23 21:16:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:16:45:INFO:Accuracy = [0.902, 0.902, 0.904, 0.9035, 0.9015, 0.901, 0.9115, 0.9105, 0.907, 0.9075]
2022-01-23 21:16:45:INFO:Loss = [0.4464060730359051, 0.45620041230140485, 0.2448432111312286, 0.24405440962073044, 0.27038207219957255, 0.2732912868843414, 0.2512345701819868, 0.2559303221758455, 0.3492624652419181, 0.341843670738308]
2022-01-23 21:16:45:INFO:-------------Training local models-------------
2022-01-23 21:33:05:INFO:-------------Aggregating local models-------------
2022-01-23 21:33:06:INFO:-------------Round number: 9-------------
2022-01-23 21:33:06:INFO:-------------Sending models-------------
2022-01-23 21:33:06:INFO:-------------Evaluating models-------------
2022-01-23 21:33:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:33:06:INFO:Accuracy = [0.9015, 0.902, 0.905, 0.905, 0.9, 0.901, 0.9115, 0.9105, 0.907, 0.9065]
2022-01-23 21:33:06:INFO:Loss = [0.47356932470356694, 0.4822476307286706, 0.2632774425052048, 0.26239598026877503, 0.29014463800849627, 0.2935092261650425, 0.28624795455034474, 0.28998895513941536, 0.37586924947027, 0.3690022548435081]
2022-01-23 21:33:06:INFO:-------------Training local models-------------
2022-01-23 21:49:26:INFO:-------------Aggregating local models-------------
2022-01-23 21:49:28:INFO:-------------Round number: 10-------------
2022-01-23 21:49:28:INFO:-------------Sending models-------------
2022-01-23 21:49:28:INFO:-------------Evaluating models-------------
2022-01-23 21:49:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 21:49:28:INFO:Accuracy = [0.9015, 0.902, 0.9045, 0.904, 0.9, 0.9, 0.9115, 0.9105, 0.9055, 0.906]
2022-01-23 21:49:28:INFO:Loss = [0.496849769452092, 0.5048267621557898, 0.28467230669484705, 0.2838365757983411, 0.3179850687025464, 0.3219766659378365, 0.319089528213226, 0.3221351543790661, 0.3986157162267773, 0.3919974696007557]
2022-01-23 21:49:28:INFO:-------------Training local models-------------
2022-01-23 22:05:48:INFO:-------------Aggregating local models-------------
2022-01-23 22:05:49:INFO:-------------Round number: 11-------------
2022-01-23 22:05:49:INFO:-------------Sending models-------------
2022-01-23 22:05:49:INFO:-------------Evaluating models-------------
2022-01-23 22:05:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:05:50:INFO:Accuracy = [0.9015, 0.902, 0.906, 0.904, 0.8995, 0.9, 0.91, 0.9075, 0.906, 0.906]
2022-01-23 22:05:50:INFO:Loss = [0.5164029946674418, 0.5239207845217606, 0.3102019727019069, 0.3094693568044022, 0.3545791560252837, 0.35911988428706537, 0.34937408419136773, 0.35186082235377397, 0.41901877210402744, 0.41263066444334984]
2022-01-23 22:05:50:INFO:-------------Training local models-------------
2022-01-23 22:22:09:INFO:-------------Aggregating local models-------------
2022-01-23 22:22:11:INFO:-------------Round number: 12-------------
2022-01-23 22:22:11:INFO:-------------Sending models-------------
2022-01-23 22:22:11:INFO:-------------Evaluating models-------------
2022-01-23 22:22:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:22:11:INFO:Accuracy = [0.9015, 0.902, 0.905, 0.9045, 0.9, 0.9005, 0.907, 0.9055, 0.906, 0.9055]
2022-01-23 22:22:11:INFO:Loss = [0.5330899473643512, 0.5402156763379026, 0.33741236893692983, 0.3368604474722815, 0.3961780149202241, 0.40104268164614043, 0.37950285945262296, 0.38152405784421717, 0.44343087868728615, 0.43722690361064454]
2022-01-23 22:22:11:INFO:-------------Training local models-------------
2022-01-23 22:38:31:INFO:-------------Aggregating local models-------------
2022-01-23 22:38:32:INFO:-------------Round number: 13-------------
2022-01-23 22:38:32:INFO:-------------Sending models-------------
2022-01-23 22:38:33:INFO:-------------Evaluating models-------------
2022-01-23 22:38:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:38:33:INFO:Accuracy = [0.9015, 0.9015, 0.906, 0.906, 0.9005, 0.9005, 0.9045, 0.903, 0.9055, 0.9055]
2022-01-23 22:38:33:INFO:Loss = [0.5479796124436689, 0.554792838819776, 0.3629072436266142, 0.36241260074129966, 0.4385511046675674, 0.44362005572256746, 0.4099358853272861, 0.41157974046982415, 0.46496097889903465, 0.4590456679055933]
2022-01-23 22:38:33:INFO:-------------Training local models-------------
2022-01-23 22:54:53:INFO:-------------Aggregating local models-------------
2022-01-23 22:54:54:INFO:-------------Round number: 14-------------
2022-01-23 22:54:54:INFO:-------------Sending models-------------
2022-01-23 22:54:54:INFO:-------------Evaluating models-------------
2022-01-23 22:54:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 22:54:55:INFO:Accuracy = [0.9015, 0.9015, 0.908, 0.907, 0.8995, 0.9005, 0.903, 0.9015, 0.9065, 0.9065]
2022-01-23 22:54:55:INFO:Loss = [0.5607785719865206, 0.5672844244027146, 0.3849958453920408, 0.3845683990541147, 0.47898854988234235, 0.4843879574622406, 0.4372465923501295, 0.43860169210383904, 0.4702774698715075, 0.4648564848557726]
2022-01-23 22:54:55:INFO:-------------Training local models-------------
2022-01-23 23:11:15:INFO:-------------Aggregating local models-------------
2022-01-23 23:11:16:INFO:-------------Round number: 15-------------
2022-01-23 23:11:16:INFO:-------------Sending models-------------
2022-01-23 23:11:16:INFO:-------------Evaluating models-------------
2022-01-23 23:11:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 23:11:17:INFO:Accuracy = [0.9015, 0.9015, 0.911, 0.909, 0.8995, 0.9, 0.9025, 0.9015, 0.908, 0.907]
2022-01-23 23:11:17:INFO:Loss = [0.5726229349827918, 0.5788627451522188, 0.4021761462696304, 0.40173518299052374, 0.51440583718977, 0.5201564656024857, 0.46215896357352904, 0.463270771210955, 0.4833017895951343, 0.478094051901644]
2022-01-23 23:11:17:INFO:-------------Training local models-------------
2022-01-23 23:23:47:INFO:-------------Aggregating local models-------------
2022-01-23 23:23:48:INFO:-------------Round number: 16-------------
2022-01-23 23:23:48:INFO:-------------Sending models-------------
2022-01-23 23:23:48:INFO:-------------Evaluating models-------------
2022-01-23 23:23:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 23:23:48:INFO:Accuracy = [0.9015, 0.9015, 0.91, 0.91, 0.8995, 0.8995, 0.9035, 0.9025, 0.9075, 0.907]
2022-01-23 23:23:48:INFO:Loss = [0.5852825489302631, 0.5913002951898306, 0.41166426670679357, 0.411099535041285, 0.545532724662553, 0.5513949109066744, 0.48457539957598783, 0.4854676764673059, 0.4959553608892747, 0.49079313377696965]
2022-01-23 23:23:48:INFO:-------------Training local models-------------
2022-01-23 23:31:56:INFO:-------------Aggregating local models-------------
2022-01-23 23:31:57:INFO:-------------Round number: 17-------------
2022-01-23 23:31:57:INFO:-------------Sending models-------------
2022-01-23 23:31:57:INFO:-------------Evaluating models-------------
2022-01-23 23:31:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 23:31:57:INFO:Accuracy = [0.9015, 0.902, 0.908, 0.91, 0.8995, 0.8995, 0.903, 0.9025, 0.908, 0.9075]
2022-01-23 23:31:57:INFO:Loss = [0.5950249244469887, 0.6008326367475092, 0.4200348378271883, 0.4194917819040711, 0.5716087032302312, 0.5773430754899891, 0.5049410469247959, 0.5057174109384505, 0.5078508610831705, 0.5026677168307288]
2022-01-23 23:31:57:INFO:-------------Training local models-------------
2022-01-23 23:40:05:INFO:-------------Aggregating local models-------------
2022-01-23 23:40:05:INFO:-------------Round number: 18-------------
2022-01-23 23:40:05:INFO:-------------Sending models-------------
2022-01-23 23:40:05:INFO:-------------Evaluating models-------------
2022-01-23 23:40:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 23:40:06:INFO:Accuracy = [0.9015, 0.902, 0.9065, 0.9085, 0.8995, 0.8995, 0.903, 0.9025, 0.9085, 0.908]
2022-01-23 23:40:06:INFO:Loss = [0.6044848103245386, 0.6100833683842211, 0.4290290178232681, 0.4282754811891209, 0.5961727921148849, 0.6018773247598801, 0.5270726497212308, 0.5277807899943582, 0.5195830924918482, 0.5143537077070505]
2022-01-23 23:40:06:INFO:-------------Training local models-------------
2022-01-23 23:48:13:INFO:-------------Aggregating local models-------------
2022-01-23 23:48:14:INFO:-------------Round number: 19-------------
2022-01-23 23:48:14:INFO:-------------Sending models-------------
2022-01-23 23:48:14:INFO:-------------Evaluating models-------------
2022-01-23 23:48:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 23:48:14:INFO:Accuracy = [0.902, 0.902, 0.9085, 0.908, 0.8995, 0.8995, 0.903, 0.9025, 0.9085, 0.9075]
2022-01-23 23:48:14:INFO:Loss = [0.6136590778762183, 0.6190880854332136, 0.4390026781355118, 0.4381544891210069, 0.620461012641681, 0.6261115113649793, 0.5405799197129454, 0.5411289995408879, 0.5315828282140501, 0.5263829418781825]
2022-01-23 23:48:14:INFO:-------------Training local models-------------
2022-01-23 23:56:22:INFO:-------------Aggregating local models-------------
2022-01-23 23:56:23:INFO:-------------Round number: 20-------------
2022-01-23 23:56:23:INFO:-------------Sending models-------------
2022-01-23 23:56:23:INFO:-------------Evaluating models-------------
2022-01-23 23:56:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-23 23:56:23:INFO:Accuracy = [0.9025, 0.902, 0.9085, 0.909, 0.8995, 0.8995, 0.9025, 0.9025, 0.908, 0.908]
2022-01-23 23:56:23:INFO:Loss = [0.6222231247726085, 0.6274980850646898, 0.44503281300712844, 0.4438266229355577, 0.6435797608859503, 0.6491583973562228, 0.555453035922983, 0.5558950197168088, 0.5431421280150971, 0.5379403837920108]
2022-01-23 23:56:23:INFO:-------------Training local models-------------
2022-01-24 00:04:31:INFO:-------------Aggregating local models-------------
2022-01-24 00:04:32:INFO:-------------Round number: 21-------------
2022-01-24 00:04:32:INFO:-------------Sending models-------------
2022-01-24 00:04:32:INFO:-------------Evaluating models-------------
2022-01-24 00:04:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 00:04:32:INFO:Accuracy = [0.9025, 0.9025, 0.908, 0.908, 0.8995, 0.8995, 0.9025, 0.902, 0.9085, 0.9085]
2022-01-24 00:04:32:INFO:Loss = [0.6303485867127165, 0.6354890797724693, 0.4527753846148698, 0.4512903452176033, 0.6659810493349141, 0.671656689116935, 0.5683397971490194, 0.5686208187231386, 0.5534859009048887, 0.5483513968312763]
2022-01-24 00:04:32:INFO:-------------Training local models-------------
2022-01-24 00:12:40:INFO:-------------Aggregating local models-------------
2022-01-24 00:12:41:INFO:-------------Round number: 22-------------
2022-01-24 00:12:41:INFO:-------------Sending models-------------
2022-01-24 00:12:41:INFO:-------------Evaluating models-------------
2022-01-24 00:12:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 00:12:41:INFO:Accuracy = [0.9025, 0.9025, 0.9085, 0.9075, 0.8995, 0.8995, 0.903, 0.9025, 0.9085, 0.908]
2022-01-24 00:12:41:INFO:Loss = [0.6378779336269872, 0.6428846846329179, 0.46392475795582866, 0.46218503226573376, 0.6881879164666316, 0.693884875691765, 0.5803262897085005, 0.5804996874276185, 0.5629028343650134, 0.5578816463827024]
2022-01-24 00:12:41:INFO:-------------Training local models-------------
2022-01-24 00:20:49:INFO:-------------Aggregating local models-------------
2022-01-24 00:20:50:INFO:-------------Round number: 23-------------
2022-01-24 00:20:50:INFO:-------------Sending models-------------
2022-01-24 00:20:50:INFO:-------------Evaluating models-------------
2022-01-24 00:20:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 00:20:50:INFO:Accuracy = [0.9025, 0.903, 0.9075, 0.909, 0.8995, 0.8995, 0.903, 0.903, 0.9085, 0.908]
2022-01-24 00:20:50:INFO:Loss = [0.6449309349298347, 0.6498349881672766, 0.4750282059034362, 0.47305104814167864, 0.7112345212579385, 0.7169768500098144, 0.5910741776440773, 0.5911049767164513, 0.5715373191227627, 0.566531860627947]
2022-01-24 00:20:50:INFO:-------------Training local models-------------
2022-01-24 00:28:58:INFO:-------------Aggregating local models-------------
2022-01-24 00:28:58:INFO:-------------Round number: 24-------------
2022-01-24 00:28:58:INFO:-------------Sending models-------------
2022-01-24 00:28:58:INFO:-------------Evaluating models-------------
2022-01-24 00:28:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 00:28:58:INFO:Accuracy = [0.9025, 0.9035, 0.907, 0.908, 0.8995, 0.8995, 0.903, 0.903, 0.908, 0.908]
2022-01-24 00:28:58:INFO:Loss = [0.6516924591638599, 0.6564916914080641, 0.48677617055564043, 0.48474222813256346, 0.7348778310377384, 0.7404048118007267, 0.6018917041958047, 0.6018435160578519, 0.579885923481197, 0.5750596049560045]
2022-01-24 00:28:58:INFO:-------------Training local models-------------
2022-01-24 00:37:06:INFO:-------------Aggregating local models-------------
2022-01-24 00:37:06:INFO:-------------Round number: 25-------------
2022-01-24 00:37:06:INFO:-------------Sending models-------------
2022-01-24 00:37:06:INFO:-------------Evaluating models-------------
2022-01-24 00:37:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 00:37:07:INFO:Accuracy = [0.9025, 0.9035, 0.9065, 0.908, 0.8995, 0.8995, 0.903, 0.9025, 0.908, 0.907]
2022-01-24 00:37:07:INFO:Loss = [0.6581539334444642, 0.6628657005559034, 0.4976805832382524, 0.49571445914225476, 0.7588202762965011, 0.7644609538348959, 0.6122164620132026, 0.6120486683599665, 0.5882323848733904, 0.5832579173755221]
2022-01-24 00:37:07:INFO:-------------Training local models-------------
2022-01-24 00:45:14:INFO:-------------Aggregating local models-------------
2022-01-24 00:45:15:INFO:-------------Round number: 26-------------
2022-01-24 00:45:15:INFO:-------------Sending models-------------
2022-01-24 00:45:15:INFO:-------------Evaluating models-------------
2022-01-24 00:45:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 00:45:15:INFO:Accuracy = [0.9035, 0.9035, 0.9055, 0.907, 0.8995, 0.8995, 0.903, 0.9025, 0.9075, 0.907]
2022-01-24 00:45:15:INFO:Loss = [0.6643554442918684, 0.6689855303622607, 0.5089572026254245, 0.5069968626701666, 0.7819139561783232, 0.7874372268042862, 0.6225124705229973, 0.6223098395528723, 0.5960781482360289, 0.5911559401834893]
2022-01-24 00:45:15:INFO:-------------Training local models-------------
2022-01-24 00:53:23:INFO:-------------Aggregating local models-------------
2022-01-24 00:53:23:INFO:-------------Round number: 27-------------
2022-01-24 00:53:23:INFO:-------------Sending models-------------
2022-01-24 00:53:23:INFO:-------------Evaluating models-------------
2022-01-24 00:53:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 00:53:23:INFO:Accuracy = [0.9035, 0.9035, 0.906, 0.9065, 0.8995, 0.8995, 0.903, 0.9025, 0.9075, 0.907]
2022-01-24 00:53:23:INFO:Loss = [0.6702809052624616, 0.6748495763767096, 0.5179957703774563, 0.5161100607327171, 0.8039935822901498, 0.8093739228178493, 0.6328489080247891, 0.6325935489829135, 0.6037402808172374, 0.599192511579895]
2022-01-24 00:53:23:INFO:-------------Training local models-------------
2022-01-24 01:01:31:INFO:-------------Aggregating local models-------------
2022-01-24 01:01:32:INFO:-------------Round number: 28-------------
2022-01-24 01:01:32:INFO:-------------Sending models-------------
2022-01-24 01:01:32:INFO:-------------Evaluating models-------------
2022-01-24 01:01:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 01:01:32:INFO:Accuracy = [0.9035, 0.9035, 0.906, 0.9055, 0.8995, 0.8995, 0.903, 0.902, 0.907, 0.907]
2022-01-24 01:01:32:INFO:Loss = [0.6759170326305138, 0.6804076464149148, 0.5284262246621438, 0.5266198290470129, 0.8245701952083436, 0.8298552528711298, 0.6424291949824692, 0.6421661963146107, 0.6104841776130343, 0.6057580760197198]
2022-01-24 01:01:32:INFO:-------------Training local models-------------
2022-01-24 01:09:40:INFO:-------------Aggregating local models-------------
2022-01-24 01:09:41:INFO:-------------Round number: 29-------------
2022-01-24 01:09:41:INFO:-------------Sending models-------------
2022-01-24 01:09:41:INFO:-------------Evaluating models-------------
2022-01-24 01:09:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 01:09:41:INFO:Accuracy = [0.9035, 0.9035, 0.905, 0.905, 0.8995, 0.8995, 0.9025, 0.902, 0.907, 0.907]
2022-01-24 01:09:41:INFO:Loss = [0.6813874617774672, 0.6858077956803299, 0.5379376754946861, 0.536202251200848, 0.8435933921450669, 0.8545346585103288, 0.6518257414529216, 0.651714098361117, 0.616726133926386, 0.6121074333576871]
2022-01-24 01:09:41:INFO:-------------Training local models-------------
2022-01-24 01:17:48:INFO:-------------Aggregating local models-------------
2022-01-24 01:17:49:INFO:-------------Round number: 30-------------
2022-01-24 01:17:49:INFO:-------------Sending models-------------
2022-01-24 01:17:49:INFO:-------------Evaluating models-------------
2022-01-24 01:17:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 01:17:49:INFO:Accuracy = [0.9035, 0.9035, 0.905, 0.9045, 0.8995, 0.8995, 0.9025, 0.902, 0.907, 0.907]
2022-01-24 01:17:49:INFO:Loss = [0.6866331166512282, 0.6909529424311132, 0.5466711899200163, 0.5449247509415727, 0.8611667605382536, 0.8715140687325402, 0.6605543225623478, 0.6603206855374992, 0.6225605133691715, 0.6178396328843518]
2022-01-24 01:17:49:INFO:-------------Training local models-------------
2022-01-24 01:25:57:INFO:-------------Aggregating local models-------------
2022-01-24 01:25:58:INFO:-------------Round number: 31-------------
2022-01-24 01:25:58:INFO:-------------Sending models-------------
2022-01-24 01:25:58:INFO:-------------Evaluating models-------------
2022-01-24 01:25:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 01:25:58:INFO:Accuracy = [0.9035, 0.9035, 0.9055, 0.905, 0.8995, 0.8995, 0.9025, 0.9015, 0.907, 0.907]
2022-01-24 01:25:58:INFO:Loss = [0.6917383706696455, 0.6960411290368029, 0.5562966660843813, 0.5545375403196886, 0.8784589404363032, 0.8888373150023654, 0.668731627112993, 0.6684308390063961, 0.6283911919282218, 0.6237712376638228]
2022-01-24 01:25:58:INFO:-------------Training local models-------------
2022-01-24 01:34:06:INFO:-------------Aggregating local models-------------
2022-01-24 01:34:06:INFO:-------------Round number: 32-------------
2022-01-24 01:34:06:INFO:-------------Sending models-------------
2022-01-24 01:34:06:INFO:-------------Evaluating models-------------
2022-01-24 01:34:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 01:34:06:INFO:Accuracy = [0.9035, 0.9035, 0.906, 0.905, 0.8995, 0.8995, 0.902, 0.9015, 0.907, 0.9065]
2022-01-24 01:34:06:INFO:Loss = [0.6967794213061097, 0.7010338520028199, 0.5632380074130197, 0.5610738424060401, 0.8951412526876084, 0.9052981221861955, 0.676456849601891, 0.6762818443109608, 0.6337809988392109, 0.6290902572851337]
2022-01-24 01:34:06:INFO:-------------Training local models-------------
2022-01-24 01:42:14:INFO:-------------Aggregating local models-------------
2022-01-24 01:42:15:INFO:-------------Round number: 33-------------
2022-01-24 01:42:15:INFO:-------------Sending models-------------
2022-01-24 01:42:15:INFO:-------------Evaluating models-------------
2022-01-24 01:42:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 01:42:15:INFO:Accuracy = [0.9035, 0.9035, 0.9055, 0.905, 0.8995, 0.8995, 0.902, 0.902, 0.9075, 0.9065]
2022-01-24 01:42:15:INFO:Loss = [0.7015835403055461, 0.7057692030308317, 0.5709488372116539, 0.5747416845564658, 0.9105304136068298, 0.9205386216589432, 0.6838177079132037, 0.6835985679330406, 0.6388128040763149, 0.633977246224822]
2022-01-24 01:42:15:INFO:-------------Training local models-------------
2022-01-24 01:50:23:INFO:-------------Aggregating local models-------------
2022-01-24 01:50:23:INFO:-------------Round number: 34-------------
2022-01-24 01:50:23:INFO:-------------Sending models-------------
2022-01-24 01:50:23:INFO:-------------Evaluating models-------------
2022-01-24 01:50:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 01:50:24:INFO:Accuracy = [0.9035, 0.9035, 0.9055, 0.9045, 0.8995, 0.8995, 0.902, 0.902, 0.9075, 0.9065]
2022-01-24 01:50:24:INFO:Loss = [0.7062914104394622, 0.7105128349272946, 0.5779302234779606, 0.5815715207416361, 0.9248666225217675, 0.9349293671267332, 0.6912992071130247, 0.6911644555620114, 0.6436272270004337, 0.6391005601682082]
2022-01-24 01:50:24:INFO:-------------Training local models-------------
2022-01-24 01:58:31:INFO:-------------Aggregating local models-------------
2022-01-24 01:58:32:INFO:-------------Round number: 35-------------
2022-01-24 01:58:32:INFO:-------------Sending models-------------
2022-01-24 01:58:32:INFO:-------------Evaluating models-------------
2022-01-24 01:58:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 01:58:32:INFO:Accuracy = [0.9035, 0.9035, 0.9055, 0.9045, 0.8995, 0.8995, 0.902, 0.902, 0.9075, 0.907]
2022-01-24 01:58:32:INFO:Loss = [0.7108776203493108, 0.7150492806148122, 0.5848160835124873, 0.588398642017728, 0.9383175376956387, 0.9481846381384458, 0.6983760067434559, 0.6980285958479726, 0.6482293039677642, 0.643634646454666]
2022-01-24 01:58:32:INFO:-------------Training local models-------------
2022-01-24 02:06:40:INFO:-------------Aggregating local models-------------
2022-01-24 02:06:40:INFO:-------------Round number: 36-------------
2022-01-24 02:06:40:INFO:-------------Sending models-------------
2022-01-24 02:06:40:INFO:-------------Evaluating models-------------
2022-01-24 02:06:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 02:06:40:INFO:Accuracy = [0.9035, 0.9035, 0.905, 0.9045, 0.8995, 0.8995, 0.902, 0.902, 0.908, 0.907]
2022-01-24 02:06:40:INFO:Loss = [0.7152892392778085, 0.7194547841289023, 0.5913892834412764, 0.5948853725813933, 0.9508973928388513, 0.959879151523728, 0.7054527104740373, 0.7050245801352503, 0.6526742514362922, 0.6480741361550827]
2022-01-24 02:06:40:INFO:-------------Training local models-------------
2022-01-24 02:14:48:INFO:-------------Aggregating local models-------------
2022-01-24 02:14:49:INFO:-------------Round number: 37-------------
2022-01-24 02:14:49:INFO:-------------Sending models-------------
2022-01-24 02:14:49:INFO:-------------Evaluating models-------------
2022-01-24 02:14:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 02:14:49:INFO:Accuracy = [0.9035, 0.9035, 0.905, 0.905, 0.8995, 0.8995, 0.902, 0.902, 0.9085, 0.907]
2022-01-24 02:14:49:INFO:Loss = [0.7195636190399455, 0.7236845172012636, 0.5980414473198834, 0.6015157207508309, 0.9629266605566954, 0.978594770449672, 0.7122307077027472, 0.712201619168718, 0.6569709843541659, 0.6520952828635928]
2022-01-24 02:14:49:INFO:-------------Training local models-------------
2022-01-24 02:22:57:INFO:-------------Aggregating local models-------------
2022-01-24 02:22:57:INFO:-------------Round number: 38-------------
2022-01-24 02:22:57:INFO:-------------Sending models-------------
2022-01-24 02:22:57:INFO:-------------Evaluating models-------------
2022-01-24 02:22:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 02:22:57:INFO:Accuracy = [0.9035, 0.9035, 0.905, 0.9055, 0.9, 0.8995, 0.902, 0.902, 0.9085, 0.9075]
2022-01-24 02:22:57:INFO:Loss = [0.7237101066642936, 0.7278381135040946, 0.6038486607352752, 0.6072048014875691, 0.9742396857503082, 0.9882990031916051, 0.7187020676637985, 0.7186298124782298, 0.6613393668589651, 0.6566459240028962]
2022-01-24 02:22:57:INFO:-------------Training local models-------------
2022-01-24 02:31:05:INFO:-------------Aggregating local models-------------
2022-01-24 02:31:06:INFO:-------------Round number: 39-------------
2022-01-24 02:31:06:INFO:-------------Sending models-------------
2022-01-24 02:31:06:INFO:-------------Evaluating models-------------
2022-01-24 02:31:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 02:31:06:INFO:Accuracy = [0.9035, 0.9035, 0.906, 0.9055, 0.9, 0.8995, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 02:31:06:INFO:Loss = [0.7277615020719168, 0.7318729939014702, 0.6104031662081979, 0.6136803717827206, 0.985188564562668, 1.010035162895474, 0.7249195826809227, 0.7246871136136178, 0.665264494961184, 0.6662139189907066]
2022-01-24 02:31:06:INFO:-------------Training local models-------------
2022-01-24 02:39:14:INFO:-------------Aggregating local models-------------
2022-01-24 02:39:14:INFO:-------------Round number: 40-------------
2022-01-24 02:39:14:INFO:-------------Sending models-------------
2022-01-24 02:39:14:INFO:-------------Evaluating models-------------
2022-01-24 02:39:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 02:39:14:INFO:Accuracy = [0.9035, 0.903, 0.9065, 0.9055, 0.9, 0.8995, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 02:39:14:INFO:Loss = [0.7316354867136396, 0.7356934733955768, 0.6166158200619976, 0.6255384864067309, 0.9955719204114757, 1.0256357955387556, 0.730614657211936, 0.7302656542725344, 0.6691096299909077, 0.669947886366117]
2022-01-24 02:39:14:INFO:-------------Training local models-------------
2022-01-24 02:47:22:INFO:-------------Aggregating local models-------------
2022-01-24 02:47:23:INFO:-------------Round number: 41-------------
2022-01-24 02:47:23:INFO:-------------Sending models-------------
2022-01-24 02:47:23:INFO:-------------Evaluating models-------------
2022-01-24 02:47:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 02:47:23:INFO:Accuracy = [0.9035, 0.903, 0.907, 0.905, 0.9, 0.9, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 02:47:23:INFO:Loss = [0.7353908835330003, 0.7393944887320686, 0.6223096636379524, 0.6311258537346476, 1.0054927043485804, 1.0402244638522462, 0.7362210842465174, 0.7361199576981562, 0.6726815404946592, 0.6733206164394687]
2022-01-24 02:47:23:INFO:-------------Training local models-------------
2022-01-24 02:55:30:INFO:-------------Aggregating local models-------------
2022-01-24 02:55:31:INFO:-------------Round number: 42-------------
2022-01-24 02:55:31:INFO:-------------Sending models-------------
2022-01-24 02:55:31:INFO:-------------Evaluating models-------------
2022-01-24 02:55:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 02:55:31:INFO:Accuracy = [0.9035, 0.903, 0.9065, 0.905, 0.9, 0.9, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 02:55:31:INFO:Loss = [0.7390083097037404, 0.74300866389558, 0.628084662382389, 0.6370594448574594, 1.0147437795531005, 1.053426431749267, 0.7414163318362625, 0.7411066294109332, 0.6761463913964235, 0.6770063308194949]
2022-01-24 02:55:31:INFO:-------------Training local models-------------
2022-01-24 03:03:39:INFO:-------------Aggregating local models-------------
2022-01-24 03:03:39:INFO:-------------Round number: 43-------------
2022-01-24 03:03:39:INFO:-------------Sending models-------------
2022-01-24 03:03:39:INFO:-------------Evaluating models-------------
2022-01-24 03:03:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 03:03:40:INFO:Accuracy = [0.9035, 0.903, 0.9065, 0.905, 0.9, 0.9, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 03:03:40:INFO:Loss = [0.742524948385244, 0.7465443190760425, 0.6337173290990904, 0.6426738951246079, 1.0235141093968196, 1.072846770515207, 0.7462880234713338, 0.746131626353872, 0.6795457505510057, 0.6804990320424622]
2022-01-24 03:03:40:INFO:-------------Training local models-------------
2022-01-24 03:11:48:INFO:-------------Aggregating local models-------------
2022-01-24 03:11:48:INFO:-------------Round number: 44-------------
2022-01-24 03:11:48:INFO:-------------Sending models-------------
2022-01-24 03:11:48:INFO:-------------Evaluating models-------------
2022-01-24 03:11:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 03:11:48:INFO:Accuracy = [0.9035, 0.903, 0.9065, 0.906, 0.9, 0.9, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 03:11:48:INFO:Loss = [0.7459622715261958, 0.7498976068550519, 0.6396152052120669, 0.6482918088485349, 1.0318771304214351, 1.0918364830810332, 0.7504058604424244, 0.7502379171979555, 0.6829017686682164, 0.6840398445695428]
2022-01-24 03:11:48:INFO:-------------Training local models-------------
2022-01-24 03:19:56:INFO:-------------Aggregating local models-------------
2022-01-24 03:19:57:INFO:-------------Round number: 45-------------
2022-01-24 03:19:57:INFO:-------------Sending models-------------
2022-01-24 03:19:57:INFO:-------------Evaluating models-------------
2022-01-24 03:19:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 03:19:57:INFO:Accuracy = [0.9035, 0.903, 0.9065, 0.906, 0.9, 0.9, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 03:19:57:INFO:Loss = [0.749256212665523, 0.7532557128796498, 0.6451610347237875, 0.6537984459600921, 1.0402025240989587, 1.1155665046132526, 0.7544771196400688, 0.753841699471559, 0.6859434693310049, 0.6929411197274931]
2022-01-24 03:19:57:INFO:-------------Training local models-------------
2022-01-24 03:28:05:INFO:-------------Aggregating local models-------------
2022-01-24 03:28:06:INFO:-------------Round number: 46-------------
2022-01-24 03:28:06:INFO:-------------Sending models-------------
2022-01-24 03:28:06:INFO:-------------Evaluating models-------------
2022-01-24 03:28:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 03:28:06:INFO:Accuracy = [0.9035, 0.903, 0.9065, 0.906, 0.9, 0.9, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 03:28:06:INFO:Loss = [0.7524459293282689, 0.7563534829419268, 0.6503187992307176, 0.6586315247744097, 1.0480416630643503, 1.128683888589012, 0.7580442865482837, 0.7573446626981877, 0.6890405843734697, 0.6957339003925881]
2022-01-24 03:28:06:INFO:-------------Training local models-------------
2022-01-24 03:36:14:INFO:-------------Aggregating local models-------------
2022-01-24 03:36:15:INFO:-------------Round number: 47-------------
2022-01-24 03:36:15:INFO:-------------Sending models-------------
2022-01-24 03:36:15:INFO:-------------Evaluating models-------------
2022-01-24 03:36:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 03:36:15:INFO:Accuracy = [0.9035, 0.903, 0.9065, 0.906, 0.9, 0.9, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 03:36:15:INFO:Loss = [0.7556340465407629, 0.7595225159458551, 0.6555697664032778, 0.6640003141274974, 1.055718850013409, 1.140265297992937, 0.7613531418290223, 0.7614426770521732, 0.6922238989464858, 0.6987690642983125]
2022-01-24 03:36:15:INFO:-------------Training local models-------------
2022-01-24 03:44:23:INFO:-------------Aggregating local models-------------
2022-01-24 03:44:23:INFO:-------------Round number: 48-------------
2022-01-24 03:44:23:INFO:-------------Sending models-------------
2022-01-24 03:44:23:INFO:-------------Evaluating models-------------
2022-01-24 03:44:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 03:44:24:INFO:Accuracy = [0.9035, 0.903, 0.9065, 0.906, 0.9, 0.9, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 03:44:24:INFO:Loss = [0.7586995779076006, 0.762636406914794, 0.6607723433591672, 0.6694461140183193, 1.0628211120587365, 1.151860410989957, 0.764098173385537, 0.763986867902122, 0.6952709071761092, 0.7015611922215157]
2022-01-24 03:44:24:INFO:-------------Training local models-------------
2022-01-24 03:52:31:INFO:-------------Aggregating local models-------------
2022-01-24 03:52:32:INFO:-------------Round number: 49-------------
2022-01-24 03:52:32:INFO:-------------Sending models-------------
2022-01-24 03:52:32:INFO:-------------Evaluating models-------------
2022-01-24 03:52:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 03:52:32:INFO:Accuracy = [0.9035, 0.903, 0.9065, 0.906, 0.9, 0.9, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 03:52:32:INFO:Loss = [0.7617164657756803, 0.7655670654048208, 0.6656410279067131, 0.6743390801328133, 1.0696378459065727, 1.1571234558697596, 0.7665608332001284, 0.7665607756192457, 0.6982334565870133, 0.704536016650809]
2022-01-24 03:52:32:INFO:-------------Training local models-------------
2022-01-24 04:00:39:INFO:-------------Aggregating local models-------------
2022-01-24 04:00:40:INFO:-------------Round number: 50-------------
2022-01-24 04:00:40:INFO:-------------Sending models-------------
2022-01-24 04:00:40:INFO:-------------Evaluating models-------------
2022-01-24 04:00:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 04:00:40:INFO:Accuracy = [0.9035, 0.903, 0.9065, 0.906, 0.9, 0.9, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 04:00:40:INFO:Loss = [0.7646288970674959, 0.7684008039013406, 0.6701793951869149, 0.6787681561811041, 1.0764531529838224, 1.168992553752696, 0.7688883579561662, 0.7685796286969889, 0.7011120988350286, 0.7073260925395971]
2022-01-24 04:00:40:INFO:-------------Training local models-------------
2022-01-24 04:08:47:INFO:-------------Aggregating local models-------------
2022-01-24 04:08:48:INFO:-------------Round number: 51-------------
2022-01-24 04:08:48:INFO:-------------Sending models-------------
2022-01-24 04:08:48:INFO:-------------Evaluating models-------------
2022-01-24 04:08:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 04:08:48:INFO:Accuracy = [0.9035, 0.903, 0.906, 0.906, 0.9, 0.9, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 04:08:48:INFO:Loss = [0.7673730773840362, 0.771251887786866, 0.6749958226017043, 0.6832688420394334, 1.0831114068565058, 1.1798530080493492, 0.7709667272844399, 0.771052606237663, 0.7038559244677345, 0.7098837476656626]
2022-01-24 04:08:48:INFO:-------------Training local models-------------
2022-01-24 04:16:56:INFO:-------------Aggregating local models-------------
2022-01-24 04:16:56:INFO:-------------Round number: 52-------------
2022-01-24 04:16:56:INFO:-------------Sending models-------------
2022-01-24 04:16:56:INFO:-------------Evaluating models-------------
2022-01-24 04:16:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 04:16:57:INFO:Accuracy = [0.9035, 0.903, 0.906, 0.906, 0.9, 0.9, 0.902, 0.902, 0.908, 0.9075]
2022-01-24 04:16:57:INFO:Loss = [0.7701374203216801, 0.7739420522104637, 0.6786695310152027, 0.6869838284193065, 1.0894453686183625, 1.1839975109957777, 0.7730310187567738, 0.7786486279362634, 0.7064798257519669, 0.7122445146767404]
2022-01-24 04:16:57:INFO:-------------Training local models-------------
2022-01-24 04:25:04:INFO:-------------Aggregating local models-------------
2022-01-24 04:25:05:INFO:-------------Round number: 53-------------
2022-01-24 04:25:05:INFO:-------------Sending models-------------
2022-01-24 04:25:05:INFO:-------------Evaluating models-------------
2022-01-24 04:25:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 04:25:05:INFO:Accuracy = [0.9035, 0.903, 0.906, 0.906, 0.9, 0.9, 0.902, 0.902, 0.9075, 0.9075]
2022-01-24 04:25:05:INFO:Loss = [0.7728167556332665, 0.7766242514524265, 0.683143749154351, 0.691066512976704, 1.0954810898932918, 1.2012827462212043, 0.7752360330891861, 0.7805053814912754, 0.709125038284401, 0.7147865677617574]
2022-01-24 04:25:05:INFO:-------------Training local models-------------
2022-01-24 04:33:13:INFO:-------------Aggregating local models-------------
2022-01-24 04:33:14:INFO:-------------Round number: 54-------------
2022-01-24 04:33:14:INFO:-------------Sending models-------------
2022-01-24 04:33:14:INFO:-------------Evaluating models-------------
2022-01-24 04:33:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 04:33:14:INFO:Accuracy = [0.9035, 0.903, 0.906, 0.906, 0.9, 0.9, 0.902, 0.902, 0.9075, 0.9075]
2022-01-24 04:33:14:INFO:Loss = [0.7754484950713504, 0.7792068662847669, 0.6872537413003557, 0.6949870983627079, 1.1013882227161047, 1.205440821856564, 0.7771042424473762, 0.7881471472708199, 0.7116547062240443, 0.7171738158378048]
2022-01-24 04:33:14:INFO:-------------Training local models-------------
2022-01-24 04:41:22:INFO:-------------Aggregating local models-------------
2022-01-24 04:41:22:INFO:-------------Round number: 55-------------
2022-01-24 04:41:22:INFO:-------------Sending models-------------
2022-01-24 04:41:22:INFO:-------------Evaluating models-------------
2022-01-24 04:41:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 04:41:22:INFO:Accuracy = [0.9035, 0.903, 0.906, 0.906, 0.9, 0.9, 0.902, 0.902, 0.9075, 0.9075]
2022-01-24 04:41:22:INFO:Loss = [0.7779928876967915, 0.7816941502091594, 0.6916242177093409, 0.699214473156735, 1.1070619612824886, 1.2161040071747267, 0.7787847977262572, 0.7897868446907979, 0.7141110186047172, 0.7197069083083079]
2022-01-24 04:41:22:INFO:-------------Training local models-------------
2022-01-24 04:49:30:INFO:-------------Aggregating local models-------------
2022-01-24 04:49:30:INFO:-------------Round number: 56-------------
2022-01-24 04:49:30:INFO:-------------Sending models-------------
2022-01-24 04:49:30:INFO:-------------Evaluating models-------------
2022-01-24 04:49:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 04:49:31:INFO:Accuracy = [0.9035, 0.903, 0.906, 0.906, 0.8995, 0.9, 0.902, 0.902, 0.9075, 0.9075]
2022-01-24 04:49:31:INFO:Loss = [0.7804579444206411, 0.7841377860750072, 0.6953545240266976, 0.7026934596418869, 1.1125870184484483, 1.2202606922878658, 0.7803831201376397, 0.7908358417302679, 0.71648230606379, 0.722004692411565]
2022-01-24 04:49:31:INFO:-------------Training local models-------------
2022-01-24 04:57:38:INFO:-------------Aggregating local models-------------
2022-01-24 04:57:39:INFO:-------------Round number: 57-------------
2022-01-24 04:57:39:INFO:-------------Sending models-------------
2022-01-24 04:57:39:INFO:-------------Evaluating models-------------
2022-01-24 04:57:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 04:57:39:INFO:Accuracy = [0.9035, 0.903, 0.906, 0.906, 0.8995, 0.9, 0.902, 0.902, 0.9075, 0.9075]
2022-01-24 04:57:39:INFO:Loss = [0.7828967150817334, 0.7865228256422597, 0.6985923503531921, 0.7056938083901514, 1.1179569897508372, 1.224120035775968, 0.7820407805892501, 0.7925312809368734, 0.7187326691404905, 0.7239963347502908]
2022-01-24 04:57:39:INFO:-------------Training local models-------------
2022-01-24 05:05:47:INFO:-------------Aggregating local models-------------
2022-01-24 05:05:47:INFO:-------------Round number: 58-------------
2022-01-24 05:05:47:INFO:-------------Sending models-------------
2022-01-24 05:05:47:INFO:-------------Evaluating models-------------
2022-01-24 05:05:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 05:05:47:INFO:Accuracy = [0.9035, 0.903, 0.906, 0.906, 0.8995, 0.9, 0.902, 0.902, 0.907, 0.9075]
2022-01-24 05:05:47:INFO:Loss = [0.785239950414325, 0.7889873450641517, 0.7023128966703552, 0.7148803157018392, 1.12306650347723, 1.2331818752995787, 0.7837660333063468, 0.7940990916854844, 0.7209990761094559, 0.732055376630069]
2022-01-24 05:05:47:INFO:-------------Training local models-------------
2022-01-24 05:13:55:INFO:-------------Aggregating local models-------------
2022-01-24 05:13:56:INFO:-------------Round number: 59-------------
2022-01-24 05:13:56:INFO:-------------Sending models-------------
2022-01-24 05:13:56:INFO:-------------Evaluating models-------------
2022-01-24 05:13:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-24 05:13:56:INFO:Accuracy = [0.9035, 0.903, 0.906, 0.906, 0.8995, 0.9, 0.902, 0.902, 0.907, 0.9075]
2022-01-24 05:13:56:INFO:Loss = [0.7876074786096978, 0.7913882070660293, 0.7065977651242974, 0.7192510952616431, 1.1280387264439924, 1.2486380718681631, 0.785448527258086, 0.7957687270325551, 0.7232528120877305, 0.734276623879623]
2022-01-24 05:13:56:INFO:-------------Training local models-------------
2022-01-24 05:22:04:INFO:-------------Aggregating local models-------------
